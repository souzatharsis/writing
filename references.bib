@misc{KOMAScriptDoc,
	title = {{KOMA-Script Documentation Project {$\vert$} Aktive Anwender verbessern KOMA-Script.}},
	year = {2019},
	month = {Feb},
	note = {[Online; accessed 18. Feb. 2019]},
	url = {https://komascript.de}
}
@book{James2013,
abstract = {... But ESL is intended for individuals with ad- vanced training in the mathematical sciences. An Introduction to Statistical Learning (ISL) arose from the perceived need for a broader and less tech- nical treatment of these topics. ... $\backslash$n},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
booktitle = {An Introd. to Stat. Learn.},
doi = {10.1007/978-1-4614-7138-7},
eprint = {arXiv:1011.1669v3},
isbn = {978-1-4614-7137-0},
issn = {01621459},
pmid = {10911016},
title = {{An Introduction to Statistical Learning}},
url = {http://www.google.com},
year = {2013}
}

@misc{webpurify2024,
    title={WebPurify - Content Moderation API},
    author={{WebPurify}},
    year={2024},
    url={https://www.webpurify.com/}
}


@article{Battle2014,
abstract = {Understanding the consequences of regulatory variation in the human genome remains a major challenge, with important implications for understanding gene regulation and interpreting the many disease-risk variants that fall outside of protein-coding regions. Here, we provide a direct window into the regulatory consequences of genetic variation by sequencing RNA from 922 genotyped individuals. We present a comprehensive description of the distribution of regulatory variation--by the specific expression phenotypes altered, the properties of affected genes, and the genomic characteristics of regulatory variants. We detect variants influencing expression of over ten thousand genes, and through the enhanced resolution offered by RNA-sequencing, for the first time we identify thousands of variants associated with specific phenotypes including splicing and allelic expression. Evaluating the effects of both long-range intra-chromosomal and trans (cross-chromosomal) regulation, we observe modularity in the regulatory network, with three-dimensional chromosomal configuration playing a particular role in regulatory modules within each chromosome. We also observe a significant depletion of regulatory variants affecting central and critical genes, along with a trend of reduced effect sizes as variant frequency increases, providing evidence that purifying selection and buffering have limited the deleterious impact of regulatory variation on the cell. Further, generalizing beyond observed variants, we have analyzed the genomic properties of variants associated with expression and splicing and developed a Bayesian model to predict regulatory consequences of genetic variants, applicable to the interpretation of individual genomes and disease studies. Together, these results represent a critical step toward characterizing the complete landscape of human regulatory variation.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Battle, Alexis and Mostafavi, Sara and Zhu, Xiaowei and Potash, James B. and Weissman, Myrna M. and McCormick, Courtney and Haudenschild, Christian D. and Beckman, Kenneth B. and Shi, Jianxin and Mei, Rui and Urban, Alexander E. and Montgomery, Stephen B. and Levinson, Douglas F. and Koller, Daphne},
doi = {10.1101/gr.155192.113},
eprint = {NIHMS150003},
journal = {Genome Res.},
number = {1},
pages = {14--24},
pmid = {24092820},
title = {{Characterizing the genetic basis of transcriptome diversity through RNA-sequencing of 922 individuals}},
volume = {24},
year = {2014}
}

@misc{deeplearningbatch284,
      title={The Batch Issue 284: AI Product Management}, 
      author={DeepLearning.AI},
      year={2024},
      url={https://www.deeplearning.ai/the-batch/issue-284/},
      note={The Batch newsletter by DeepLearning.AI}
}


@misc{llamaparse2024github,
      title={LlamaParse: Extract structured data from text and PDFs using LLMs}, 
      author={LlamaIndex},
      year={2024},
      url={https://github.com/run-llama/llama_parse},
      note={LlamaParse}
}

@misc{chan2024dontragcacheaugmentedgeneration,
      title={Don't Do RAG: When Cache-Augmented Generation is All You Need for Knowledge Tasks}, 
      author={Brian J Chan and Chao-Ting Chen and Jui-Hung Cheng and Hen-Hsen Huang},
      year={2024},
      eprint={2412.15605},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15605}, 
}

@article{Zou2005,
abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p≫n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
author = {Zou, Hui and Hastie, Trevor},
doi = {10.1111/j.1467-9868.2005.00503.x},
journal = {J. R. Stat. Soc.},
keywords = {grouping effect,lars algorithm,lasso,p,penalization},
number = {2},
pages = {301--320},
pmid = {20713001},
title = {{Regularization and variable selection via the elastic-net}},
volume = {67},
year = {2005}
}
@article{Lappalainen2013,
abstract = {Genome sequencing projects are discovering millions of genetic variants in humans, and interpretation of their functional effects is essential for understanding the genetic basis of variation in human traits. Here we report sequencing and deep analysis of messenger RNA and microRNA from lymphoblastoid cell lines of 462 individuals from the 1000 Genomes Project--the first uniformly processed high-throughput RNA-sequencing data from multiple human populations with high-quality genome sequences. We discover extremely widespread genetic variation affecting the regulation of most genes, with transcript structure and expression level variation being equally common but genetically largely independent. Our characterization of causal regulatory variation sheds light on the cellular mechanisms of regulatory and loss-of-function variation, and allows us to infer putative causal variants for dozens of disease-associated loci. Altogether, this study provides a deep understanding of the cellular mechanisms of transcriptome variation and of the landscape of functional variants in the human genome.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Lappalainen, Tuuli and Sammeth, Michael and Friedl{\"{a}}nder, Marc R. and {'T Hoen}, Peter A.C. and Monlong, Jean and Rivas, Manuel A. and Gonz{\`{a}}lez-Porta, Mar and Kurbatova, Natalja and Griebel, Thasso and Ferreira, Pedro G. and Barann, Matthias and Wieland, Thomas and Greger, Liliana and {Van Iterson}, Maarten and Alml{\"{o}}f, Jonas and Ribeca, Paolo and Pulyakhina, Irina and Esser, Daniela and Giger, Thomas and Tikhonov, Andrew and Sultan, Marc and Bertier, Gabrielle and Macarthur, Daniel G. and Lek, Monkol and Lizano, Esther and Buermans, Henk P.J. and Padioleau, Ismael and Schwarzmayr, Thomas and Karlberg, Olof and Ongen, Halit and Kilpinen, Helena and Beltran, Sergi and Gut, Marta and Kahlem, Katja and Amstislavskiy, Vyacheslav and Stegle, Oliver and Pirinen, Matti and Montgomery, Stephen B. and Donnelly, Peter and McCarthy, Mark I. and Flicek, Paul and Strom, Tim M. and Lehrach, Hans and Schreiber, Stefan and Sudbrak, Ralf and Carracedo, {\'{A}}ngel and Antonarakis, Stylianos E. and H{\"{a}}sler, Robert and Syv{\"{a}}nen, Ann Christine and {Van Ommen}, Gert Jan and Brazma, Alvis and Meitinger, Thomas and Rosenstiel, Philip and Guig{\'{o}}, Roderic and Gut, Ivo G. and Estivill, Xavier and Dermitzakis, Emmanouil T.},
doi = {10.1038/nature12531},
eprint = {NIHMS150003},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {00280836},
journal = {Nature},
number = {7468},
pages = {506--511},
pmid = {24037378},
title = {{Transcriptome and genome sequencing uncovers functional variation in humans}},
volume = {501},
year = {2013}
}
@article{ENCODEProjectConsortium2012,
abstract = {The human genome encodes the blueprint of life, but the function of the vast majority of its nearly three billion bases is unknown. The Encyclopedia of DNA Elements (ENCODE) project has systematically mapped regions of transcription, transcription factor association, chromatin structure and histone modification. These data enabled us to assign biochemical functions for 80{\%} of the genome, in particular outside of the well-studied protein-coding regions. Many discovered candidate regulatory elements are physically associated with one another and with expressed genes, providing new insights into the mechanisms of gene regulation. The newly identified elements also show a statistical correspondence to sequence variants linked to human disease, and can thereby guide interpretation of this variation. Overall, the project provides new insights into the organization and regulation of our genes and genome, and is an expansive resource of functional annotations for biomedical research.},
author = {{ENCODE Project Consortium}, An Integrated Encyclopedia of DNA Elements in the Human},
doi = {10.1038/nature11247},
issn = {1476-4687},
journal = {Nature},
number = {7414},
pages = {57--74},
pmid = {22955616},
title = {{An integrated encyclopedia of DNA elements in the human genome.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22955616{\%}5Cnhttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3439153},
volume = {489},
year = {2012}
}
@article{Gusev2018,
abstract = {Genome-wide association studies (GWAS) have identified over 100 risk loci for schizophrenia, but the causal mechanisms remain largely unknown. We performed a transcriptome-wide association study (TWAS) integrating expression data from brain, blood, and adipose tissues across 3,693 individuals with schizophrenia GWAS of 79,845 individuals from the Psychiatric Genomics Consortium. We identified 157 genes with a transcriptome-wide significant association, of which 35 did not overlap a known GWAS locus; the largest number involved alternative splicing in brain. 42/157 genes were also associated to specific chromatin phenotypes measured in 121 independent samples (a 4-fold enrichment over background genes). This high-throughput connection of GWAS findings to specific genes, tissues, and regulatory mechanisms is an essential step toward understanding the biology of schizophrenia and moving towards therapeutic interventions.},
author = {Gusev, Alexander and Mancuso, Nicholas and Won, Hyejung and Kousi, Maria and Finucane, Hilary K. and Reshef, Yakir and Song, Lingyun and Safi, Alexias and McCarroll, Steven and Neale, Benjamin M. and Ophoff, Roel A. and O'Donovan, Michael C. and Crawford, Gregory E. and Geschwind, Daniel H. and Katsanis, Nicholas and Sullivan, Patrick F. and Pasaniuc, Bogdan and Price, Alkes L.},
doi = {10.1038/s41588-018-0092-1},
isbn = {1546-1718},
issn = {15461718},
journal = {Nat. Genet.},
keywords = {TWAS},
mendeley-tags = {TWAS},
number = {4},
pages = {538--548},
pmid = {29632383},
title = {{Transcriptome-wide association study of schizophrenia and chromatin activity yields mechanistic disease insights}},
volume = {50},
year = {2018}
}
@article{Gusev2016,
abstract = {Many genetic variants influence complex traits by modulating gene expression, thus altering the abundance of one or multiple proteins. Here we introduce a powerful strategy that integrates gene expression measurements with summary association statistics from large-scale genome-wide association studies (GWAS) to identify genes whose cis-regulated expression is associated with complex traits. We leverage expression imputation from genetic data to perform a transcriptome-wide association study (TWAS) to identify significant expression-trait associations. We applied our approaches to expression data from blood and adipose tissue measured in ∼3,000 individuals overall. We imputed gene expression into GWAS data from over 900,000 phenotype measurements to identify 69 new genes significantly associated with obesity-related traits (BMI, lipids and height). Many of these genes are associated with relevant phenotypes in the Hybrid Mouse Diversity Panel. Our results showcase the power of integrating genotype, gene expression and phenotype to gain insights into the genetic basis of complex traits.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Gusev, Alexander and Ko, Arthur and Shi, Huwenbo and Bhatia, Gaurav and Chung, Wonil and Penninx, Brenda W.J.H. and Jansen, Rick and {De Geus}, Eco J.C. and Boomsma, Dorret I. and Wright, Fred A. and Sullivan, Patrick F. and Nikkola, Elina and Alvarez, Marcus and Civelek, Mete and Lusis, Aldons J. and Lehtim{\"{a}}ki, Terho and Raitoharju, Emma and K{\"{a}}h{\"{o}}nen, Mika and Sepp{\"{a}}l{\"{a}}, Ilkka and Raitakari, Olli T. and Kuusisto, Johanna and Laakso, Markku and Price, Alkes L. and Pajukanta, P{\"{a}}ivi and Pasaniuc, Bogdan},
doi = {10.1038/ng.3506},
eprint = {15334406},
isbn = {1061-4036},
issn = {15461718},
journal = {Nat. Genet.},
keywords = {TWAS},
mendeley-tags = {TWAS},
month = {mar},
number = {3},
pages = {245--252},
pmid = {26854917},
publisher = {Nature Publishing Group},
title = {{Integrative approaches for large-scale transcriptome-wide association studies}},
url = {http://www.nature.com/articles/ng.3506 http://www.ncbi.nlm.nih.gov/pubmed/26854917 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4767558},
volume = {48},
year = {2016}
}
@article{Gamazon2015,
abstract = {Genome-wide association studies (GWAS) have identified thousands of variants robustly associated with complex traits. However, the biological mechanisms underlying these associations are, in general, not well understood. We propose a gene-based association method called PrediXcan that directly tests the molecular mechanisms through which genetic variation affects phenotype. The approach estimates the component of gene expression determined by an individual's genetic profile and correlates 'imputed' gene expression with the phenotype under investigation to identify genes involved in the etiology of the phenotype. Genetically regulated gene expression is estimated using whole-genome tissue-dependent prediction models trained with reference transcriptome data sets. PrediXcan enjoys the benefits of gene-based approaches such as reduced multiple-testing burden and a principled approach to the design of follow-up experiments. Our results demonstrate that PrediXcan can detect known and new genes associated with disease traits and provide insights into the mechanism of these associations.},
author = {Gamazon, Eric R. and Wheeler, Heather E. and Shah, Kaanan P. and Mozaffari, Sahar V. and Aquino-Michaels, Keston and Carroll, Robert J. and Eyler, Anne E. and Denny, Joshua C. and Nicolae, Dan L. and Cox, Nancy J. and Im, Hae Kyung},
doi = {10.1038/ng.3367},
isbn = {1061-4036},
issn = {15461718},
journal = {Nat. Genet.},
keywords = {TWAS},
mendeley-tags = {TWAS},
month = {sep},
number = {9},
pages = {1091--1098},
pmid = {26258848},
title = {{A gene-based association method for mapping traits using reference transcriptome data}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26258848 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4552594 http://www.nature.com/articles/ng.3367},
volume = {47},
year = {2015}
}
@misc{Lonsdale2013,
abstract = {Genome-wide association studies have identified thousands of loci for common diseases, but, for the majority of these, the mechanisms underlying disease susceptibility remain unknown. Most associated variants are not correlated with protein-coding changes, suggesting that polymorphisms in regulatory regions probably contribute to many disease phenotypes. Here we describe the Genotype-Tissue Expression (GTEx) project, which will establish a resource database and associated tissue bank for the scientific community to study the relationship between genetic variation and gene expression in human tissues.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Lonsdale, John and Thomas, Jeffrey and Salvatore, Mike and Phillips, Rebecca and Lo, Edmund and Shad, Saboor and Hasz, Richard and Walters, Gary and Garcia, Fernando and Young, Nancy and Foster, Barbara and Moser, Mike and Karasik, Ellen and Gillard, Bryan and Ramsey, Kimberley and Sullivan, Susan and Bridge, Jason and Magazine, Harold and Syron, John and Fleming, Johnelle and Siminoff, Laura and Traino, Heather and Mosavel, Maghboeba and Barker, Laura and Jewell, Scott and Rohrer, Dan and Maxim, Dan and Filkins, Dana and Harbach, Philip and Cortadillo, Eddie and Berghuis, Bree and Turner, Lisa and Hudson, Eric and Feenstra, Kristin and Sobin, Leslie and Robb, James and Branton, Phillip and Korzeniewski, Greg and Shive, Charles and Tabor, David and Qi, Liqun and Groch, Kevin and Nampally, Sreenath and Buia, Steve and Zimmerman, Angela and Smith, Anna and Burges, Robin and Robinson, Karna and Valentino, Kim and Bradbury, Deborah and Cosentino, Mark and Diaz-Mayoral, Norma and Kennedy, Mary and Engel, Theresa and Williams, Penelope and Erickson, Kenyon and Ardlie, Kristin and Winckler, Wendy and Getz, Gad and DeLuca, David and {Daniel MacArthur} and Kellis, Manolis and Thomson, Alexander and Young, Taylor and Gelfand, Ellen and Donovan, Molly and Meng, Yan and Grant, George and Mash, Deborah and Marcus, Yvonne and Basile, Margaret and Liu, Jun and Zhu, Jun and Tu, Zhidong and Cox, Nancy J. and Nicolae, Dan L. and Gamazon, Eric R. and Im, Hae Kyung and Konkashbaev, Anuar and Pritchard, Jonathan and Stevens, Matthew and Flutre, Timoth{\`{e}}e and Wen, Xiaoquan and Dermitzakis, Emmanouil T. and Lappalainen, Tuuli and Guigo, Roderic and Monlong, Jean and Sammeth, Michael and Koller, Daphne and Battle, Alexis and Mostafavi, Sara and McCarthy, Mark and Rivas, Manual and Maller, Julian and Rusyn, Ivan and Nobel, Andrew and Wright, Fred and Shabalin, Andrey and Feolo, Mike and Sharopova, Nataliya and Sturcke, Anne and Paschal, Justin and Anderson, James M. and Wilder, Elizabeth L. and Derr, Leslie K. and Green, Eric D. and Struewing, Jeffery P. and Temple, Gary and Volpi, Simona and Boyer, Joy T. and Thomson, Elizabeth J. and Guyer, Mark S. and Ng, Cathy and Abdallah, Assya and Colantuoni, Deborah and Insel, Thomas R. and Koester, Susan E. and {A Roger Little} and Bender, Patrick K. and Lehner, Thomas and Yao, Yin and Compton, Carolyn C. and Vaught, Jimmie B. and Sawyer, Sherilyn and Lockhart, Nicole C. and Demchok, Joanne and Moore, Helen F.},
booktitle = {Nat. Genet.},
doi = {10.1038/ng.2653},
eprint = {NIHMS150003},
isbn = {1061-4036},
issn = {10614036},
number = {6},
pages = {580--585},
pmid = {23715323},
title = {{The Genotype-Tissue Expression (GTEx) project}},
volume = {45},
year = {2013}
}
@article{Ramasamy2014,
abstract = {Germ-line genetic control of gene expression occurs via expression quantitative trait loci (eQTLs). We present a large, exon-specific eQTL data set covering ten human brain regions. We found that cis-eQTL signals (within 1 Mb of their target gene) were numerous, and many acted heterogeneously among regions and exons. Co-regulation analysis of shared eQTL signals produced well-defined modules of region-specific co-regulated genes, in contrast to standard coexpression analysis of the same samples. We report cis-eQTL signals for 23.1{\%} of catalogued genome-wide association study hits for adult-onset neurological disorders. The data set is publicly available via public data repositories and via http://www.braineac.org/. Our study increases our understanding of the regulation of gene expression in the human brain and will be of value to others pursuing functional follow-up of disease-associated variants.},
author = {Ramasamy, A and Trabzuni, D and Guelfi, S and Varghese, V and Smith, C and Walker, R and De, T and Consortium, U K Brain Expression and {North American Brain Expression}, Consortium and Coin, L and de Silva, R and Cookson, M R and Singleton, A B and Hardy, J and Ryten, M and Weale, M E},
doi = {10.1038/nn.3801},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1546-1726; 1097-6256},
journal = {Nat. Neurosci.},
keywords = {*Gene Expression Regulation,*Genetic Predisposition to Disease,*Quantitative Trait Loci,Adolescent,Adult,Aged,Aged, 80 and over,Brain/*anatomy {\&} histology/metabolism,Female,Gene Expression Profiling,Genetic Association Studies,Humans,Male,Middle Aged,Nervous System Diseases/*genetics/*pathology,Oligonucleotide Array Sequence Analysis,Polymorphism, Single Nucleotide,Young Adult},
number = {10},
pages = {1418--1428},
pmid = {25174004},
title = {{Genetic variability in the regulation of gene expression in ten regions of the human brain}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25174004},
volume = {17},
year = {2014}
}
@article{Visscher2008,
abstract = {Heritability allows a comparison of the relative importance of genes and environment to the variation of traits within and across populations. The concept of heritability and its definition as an estimable, dimensionless population parameter was introduced by Sewall Wright and Ronald Fisher nearly a century ago. Despite continuous misunderstandings and controversies over its use and application, heritability remains key to the response to selection in evolutionary biology and agriculture, and to the prediction of disease risk in medicine. Recent reports of substantial heritability for gene expression and new estimation methods using marker data highlight the relevance of heritability in the genomics era.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Visscher, Peter M and Hill, William G and Wray, Naomi R},
doi = {10.1038/nrg2322},
eprint = {arXiv:1011.1669v3},
issn = {1471-0064},
journal = {Nat. Rev. Genet.},
number = {4},
pages = {255--266},
pmid = {18319743},
title = {{Heritability in the genomics era--concepts and misconceptions.}},
volume = {9},
year = {2008}
}
@article{Giambartolomei2014,
abstract = {Genetic association studies, in particular the genome-wide association study design, have provided a wealth of novel insights into the aetiology of a wide range of human diseases and traits. The next challenge consists of understanding the molecular basis of these associations. The integration of multiple association datasets, including gene expression datasets, can contribute to this goal. We have developed a novel statistical methodology to assess whether two association signals are consistent with a shared causal variant. An application is the integration of disease scans with expression quantitative trait locus (eQTL) studies, but any pair of GWAS datasets can be integrated in this framework. We demonstrate the value of the approach by reanalysing a gene expression dataset in 966 liver samples with a published meta-analysis of lipid traits including {\textgreater}100, 000 individuals of European ancestry. Combining all lipid biomarkers, our reanalysis supported 29 out of 38 reported colocalisation results with eQTLs and identified 14 new colocalisation results, highlighting the value of a formal statistical test. In two cases of reported eQTL-lipid pairs (IFT172, TBKBP1) for which our analysis suggests that the eQTL pattern is not consistent with the lipid association, we identify alternative colocalisation results with GCKR and KPNB1, indicating that these genes are more likely to be causal in these genomic intervals. A key feature of the method is the ability to derive the output statistics from single SNP summary statistics, hence making it possible to perform systematic meta-analysis type comparisons across multiple GWAS datasets (http://coloc.cs.ucl.ac.uk/coloc/). Our methodology provides information about candidate causal genes in associated intervals and has direct implications for the understanding of complex diseases and the design of drugs to target disease pathways.},
archivePrefix = {arXiv},
arxivId = {1305.4022},
author = {Giambartolomei, Claudia and Vukcevic, Damjan and Schadt, Eric E. and Franke, Lude and Hingorani, Aroon D. and Wallace, Chris and Plagnol, Vincent},
doi = {10.1371/journal.pgen.1004383},
eprint = {1305.4022},
isbn = {1553-7404 (Electronic)$\backslash$r1553-7390 (Linking)},
issn = {15537404},
journal = {PLoS Genet.},
number = {5},
pmid = {24830394},
title = {{Bayesian Test for Colocalisation between Pairs of Genetic Association Studies Using Summary Statistics}},
volume = {10},
year = {2014}
}
@article{Ardlie2015,
abstract = {Understanding the functional consequences of genetic variation, and how it affects complex human disease and quantitative traits, remains a critical challenge for biomedicine. We present an analysis of RNA sequencing data from 1641 samples across 43 tissues from 175 individuals, generated as part of the pilot phase of the Genotype-Tissue Expression (GTEx) project. We describe the landscape of gene expression across tissues, catalog thousands of tissue-specific and shared regulatory expression quantitative trait loci (eQTL) variants, describe complex network relationships, and identify signals from genome-wide association studies explained by eQTLs. These findings provide a systematic understanding of the cellular and biological consequences of human genetic variation and of the heterogeneity of such effects among a diverse set of human tissues.$\backslash$nExpression, genetic variation, and tissues$\backslash$nHuman genomes show extensive genetic variation across individuals, but we have only just started documenting the effects of this variation on the regulation of gene expression. Furthermore, only a few tissues have been examined per genetic variant. In order to examine how genetic expression varies among tissues within individuals, the Genotype-Tissue Expression (GTEx) Consortium collected 1641 postmortem samples covering 54 body sites from 175 individuals. They identified quantitative genetic traits that affect gene expression and determined which of these exhibit tissue-specific expression patterns. Mel{\'{e}} et al. measured how transcription varies among tissues, and Rivas et al. looked at how truncated protein variants affect expression across tissues.$\backslash$nScience, this issue p. 648, p. 660, p. 666; see also p. 640},
author = {Ardlie, Kristin G. and DeLuca, David S. and Segr{\`{e}}, Ayellet V. and Sullivan, Timothy J. and Young, Taylor R. and Gelfand, Ellen T. and Trowbridge, Casandra A. and Maller, Julian B. and Tukiainen, Taru and Lek, Monkol and Ward, Lucas D. and Kheradpour, Pouya and Iriarte, Benjamin and Meng, Yan and Palmer, Cameron D. and Esko, T{\~{o}}nu and Winckler, Wendy and Hirschhorn, Joel N. and Kellis, Manolis and MacArthur, Daniel G. and Getz, Gad and Shabalin, Andrey A. and Li, Gen and Zhou, Yi Hui and Nobel, Andrew B. and Rusyn, Ivan and Wright, Fred A. and Lappalainen, Tuuli and Ferreira, Pedro G. and Ongen, Halit and Rivas, Manuel A. and Battle, Alexis and Mostafavi, Sara and Monlong, Jean and Sammeth, Michael and Mel{\'{e}}, Marta and Reverter, Ferran and Goldmann, Jakob M. and Koller, Daphne and Guig{\'{o}}, Roderic and McCarthy, Mark I. and Dermitzakis, Emmanouil T. and Gamazon, Eric R. and Im, Hae Kyung and Konkashbaev, Anuar and Nicolae, Dan L. and Cox, Nancy J. and Flutre, Timoth{\'{e}}e and Wen, Xiaoquan and Stephens, Matthew and Pritchard, Jonathan K. and Tu, Zhidong and Zhang, Bin and Huang, Tao and Long, Quan and Lin, Luan and Yang, Jialiang and Zhu, Jun and Liu, Jun and Brown, Amanda and Mestichelli, Bernadette and Tidwell, Denee and Lo, Edmund and Salvatore, Michael and Shad, Saboor and Thomas, Jeffrey A. and Lonsdale, John T. and Moser, Michael T. and Gillard, Bryan M. and Karasik, Ellen and Ramsey, Kimberly and Choi, Christopher and Foster, Barbara A. and Syron, John and Fleming, Johnell and Magazine, Harold and Hasz, Rick and Walters, Gary D. and Bridge, Jason P. and Miklos, Mark and Sullivan, Susan and Barker, Laura K. and Traino, Heather M. and Mosavel, Maghboeba and Siminoff, Laura A. and Valley, Dana R. and Rohrer, Daniel C. and Jewell, Scott D. and Branton, Philip A. and Sobin, Leslie H. and Barcus, Mary and Qi, Liqun and McLean, Jeffrey and Hariharan, Pushpa and Um, Ki Sung and Wu, Shenpei and Tabor, David and Shive, Charles and Smith, Anna M. and Buia, Stephen A. and Undale, Anita H. and Robinson, Karna L. and Roche, Nancy and Valentino, Kimberly M. and Britton, Angela and Burges, Robin and Bradbury, Debra and Hambright, Kenneth W. and Seleski, John and Korzeniewski, Greg E. and Erickson, Kenyon and Marcus, Yvonne and Tejada, Jorge and Taherian, Mehran and Lu, Chunrong and Basile, Margaret and Mash, Deborah C. and Volpi, Simona and Struewing, Jeffery P. and Temple, Gary F. and Boyer, Joy and Colantuoni, Deborah and Little, Roger and Koester, Susan and Carithers, Latarsha J. and Moore, Helen M. and Guan, Ping and Compton, Carolyn and Sawyer, Sherilyn J. and Demchok, Joanne P. and Vaught, Jimmie B. and Rabiner, Chana A. and Lockhart},
doi = {10.1126/science.1262110},
isbn = {0036-8075},
issn = {10959203},
journal = {Science (80-. ).},
number = {6235},
pages = {648--660},
pmid = {25954001},
title = {{The Genotype-Tissue Expression (GTEx) pilot analysis: Multitissue gene regulation in humans}},
volume = {348},
year = {2015}
}




---
---

@misc{wei2022emergentabilitieslargelanguage,
      title={Emergent Abilities of Large Language Models}, 
      author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
      year={2022},
      eprint={2206.07682},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.07682}, 
}

@misc{liang2024controllabletextgenerationlarge,
      title={Controllable Text Generation for Large Language Models: A Survey}, 
      author={Xun Liang and Hanyu Wang and Yezhaohui Wang and Shichao Song and Jiawei Yang and Simin Niu and Jie Hu and Dan Liu and Shunyu Yao and Feiyu Xiong and Zhiyu Li},
      year={2024},
      eprint={2408.12599},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.12599}, 
}

@misc{hf2024quantization,
      title={Quantization in Optimum},
      author={HuggingFace},
      year={2024s},
      howpublished={\url{https://huggingface.co/docs/optimum/en/concept_guides/quantization}},
      note={Accessed: 2024}
}


@misc{mistraltechnology2024,
      title={Mistral Technology and Pricing},
      author={Mistral AI},
      year={2024a},
      howpublished={\url{https://mistral.ai/technology/}},
      note={Accessed: 2024}
}


@misc{hf2024yearinreview,
      title={Open Source AI Year in Review 2024},
      author={HuggingFace},
      year={2024t},
      howpublished={\url{https://huggingface.co/spaces/huggingface/open-source-ai-year-in-review-2024}},
      note={Accessed: 2024}
}

@misc{penedo2024finewebdatasetsdecantingweb,
      title={The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale}, 
      author={Guilherme Penedo and Hynek Kydlicek and Loubna Ben allal and Anton Lozhkov and Margaret Mitchell and Colin Raffel and Leandro Von Werra and Thomas Wolf},
      year={2024},
      eprint={2406.17557},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.17557}, 
}

@misc{deepseek2024tweet,
    title={DeepSeek-V3 Announcement},
    author={{DeepSeek}},
    year={2024},
    howpublished={Tweet},
    url={https://x.com/deepseek_ai/status/1872242663489188088}
}

@misc{salesforce2024gifteval,
    title={GIFT-Eval: General TIme Series ForecasTing Model Evaluation},
    author={{Salesforce}},
    year={2024},
    howpublished={Website},
    url={https://huggingface.co/spaces/Salesforce/GIFT-Eval}
}

@misc{wang2024comprehensivesurveysmalllanguage,
      title={A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness}, 
      author={Fali Wang and Zhiwei Zhang and Xianren Zhang and Zongyu Wu and Tzuhao Mo and Qiuhao Lu and Wanjing Wang and Rui Li and Junjie Xu and Xianfeng Tang and Qi He and Yao Ma and Ming Huang and Suhang Wang},
      year={2024},
      eprint={2411.03350},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.03350}, 
}

@misc{harvardlawreview2024nyt,
      title={NYT v. OpenAI: The Times's About-Face},
      author={Harvard Law Review},
      year={2024},
      howpublished={\url{https://harvardlawreview.org/blog/2024/04/nyt-v-openai-the-timess-about-face/}},
      note={Accessed: 2024}
}



@misc{outlines2024,
      title={Type-Safe Structured Output from LLMs},
      author={Outlines},
      year={2024},
      howpublished={\url{https://dottxt-ai.github.io/outlines/latest/}},
      note={Accessed: 2024}
}

@misc{Hermes-2-Theta-Llama-3-8B,
      title={Hermes-2-Theta-Llama-3-8B},
      author={NousResearch},
      year={2024},
      howpublished={\url{https://huggingface.co/NousResearch/Hermes-2-Theta-Llama-3-8B}},
      note={Accessed: 2024}
}



@misc{tam2024letspeakfreelystudy,
      title={Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models}, 
      author={Zhi Rui Tam and Cheng-Kuang Wu and Yi-Lin Tsai and Chieh-Yen Lin and Hung-yi Lee and Yun-Nung Chen},
      year={2024},
      eprint={2408.02442},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.02442}, 
}

@misc{dottxt2024saywhatyoumean,
      title={Say What You Mean: Structured Output for LLMs},
      author={Dottxt},
      year={2024},
      howpublished={\url{https://blog.dottxt.co/say-what-you-mean.html}},
      note={Accessed: 2024}
}

@misc{aider2024codejson,
      title={Code in JSON: Structured Output for LLMs},
      author={Aider},
      year={2024},
      howpublished={\url{https://aider.chat/2024/08/14/code-in-json.html}},
      note={Accessed: 2024}
}

@misc{dottxt2024demos,
      title={Say What You Mean: Demos},
      author={Dottxt},
      year={2024},
      howpublished={\url{https://github.com/dottxt-ai/demos/tree/main/say-what-you-mean}},
      note={Accessed: 2024}
}

@misc{li2024leveraginglargelanguagemodels,
      title={Leveraging Large Language Models for NLG Evaluation: Advances and Challenges}, 
      author={Zhen Li and Xiaohan Xu and Tao Shen and Can Xu and Jia-Chen Gu and Yuxuan Lai and Chongyang Tao and Shuai Ma},
      year={2024},
      eprint={2401.07103},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.07103}, 
}

@misc{huggingface2024llmjudge,
      title={LLM as a Judge},
      author={HuggingFace},
      year={2024},
      howpublished={\url{https://huggingface.co/learn/cookbook/en/llm_judge}},
      note={Accessed: 2024}
}

@misc{nickel2024freedeliveryserviceepistemic,
      title={No Free Delivery Service: Epistemic limits of passive data collection in complex social systems}, 
      author={Maximilian Nickel},
      year={2024},
      eprint={2411.13653},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.13653}, 
}

@misc{judgearena2024,
      title={Judge Arena: Evaluating LLM Outputs with LLMs},
      author={Judge Arena},
      year={2024}, 
      howpublished={\url{https://judgearena.com/}},
      note={Accessed: 2024}
}

@misc{artificialanalysis2024providers,
      title={LLM Provider Leaderboards},
      author={Artificial Analysis},
      year={2024},
      howpublished={\url{https://artificialanalysis.ai/leaderboards/providers}},
      note={Accessed: 2024}
}


@misc{artificialanalysis2024methodology,
      title={Methodology},
      author={Artificial Analysis},
      year={2024},
      howpublished={\url{https://artificialanalysis.ai/methodology}},
      note={Accessed: December 22, 2024}
}


@misc{lighteval,
  author = {Fourrier, Clémentine and Habib, Nathan and Wolf, Thomas and Tunstall, Lewis},
  title = {LightEval: A lightweight framework for LLM evaluation},
  year = {2023},
  version = {0.5.0},
  url = {https://github.com/huggingface/lighteval}
}

@misc{artificialanalysis2024llmproviders,
      title={LLM Provider Leaderboards},
      author={Artificial Analysis},
      year={2024},
      howpublished={\url{https://artificialanalysis.ai/leaderboards/providers}},
      note={Accessed: 2024}
}


@misc{allal2024SmolLM2,
      title={SmolLM2 - with great data, comes great performance}, 
      author={Loubna Ben Allal and Anton Lozhkov and Elie Bakouch and Gabriel Martín Blázquez and Lewis Tunstall and Agustín Piqueres and Andres Marafioti and Cyril Zakka and Leandro von Werra and Thomas Wolf},
      year={2024},
}

@article{hui2024qwen2,
      title={Qwen2.5 - Coder Technical Report},
      author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Dang, Kai and others},
      journal={arXiv preprint arXiv:2409.12186},
      year={2024}
}

@article{qwen2,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
      journal={arXiv preprint arXiv:2407.10671},
      year={2024}
}

@misc{lighteval_tasks,
      title={Available Tasks - LightEval Wiki},
      author={HuggingFace},
      year={2024},
      howpublished={\url{https://github.com/huggingface/lighteval/wiki/Available-Tasks}},
      note={Accessed: 2024}
}

@misc{lighteval_metrics,
      title={Metric List - LightEval Wiki},
      author={HuggingFace},
      year={2024},
      howpublished={\url{https://github.com/huggingface/lighteval/wiki/Metric-List}},
      note={Accessed: 2024}
}

@misc{lighteval_server,
      title={Evaluate the model on a server or container - LightEval Wiki},
      author={HuggingFace},
      year={2024},
      howpublished={\url{https://github.com/huggingface/lighteval/wiki/Evaluate-the-model-on-a-server-or-container}},
      note={Accessed: 2024}
}



@misc{gpt2docs,
      title={GPT-2 Documentation - HuggingFace Transformers},
      author={HuggingFace},
      year={2024},
      howpublished={\url{https://huggingface.co/docs/transformers/model_doc/gpt2}},
      note={Accessed: 2024}
}






@misc{qwen_openrouter_usage,
      title={Qwen Usage on OpenRouter},
      author={{OpenRouter}},
      year={2024},
      howpublished={\url{https://x.com/OpenRouterAI/status/1864549260089327936}},
      note={Accessed: 12/06/2024}
}

@misc{hf_num_models,
      title={Number of Models on HuggingFace},
      author={{HuggingFace}},
      year={2024},
      howpublished={\url{https://huggingface.co/spaces/huggingface/open-source-ai-year-in-review-2024?day=4}},
      note={Accessed: 12/06/2024}
}

@misc{meta_llama_models,
      title={Meta Llama Models on HuggingFace},
      author={{Meta AI}},
      year={2024},
      howpublished={\url{https://huggingface.co/meta-llama}},
      note={Accessed: 2024}
}

@misc{promptfoo,
      title={PromptFoo - Open-source prompt engineering toolkit},
      author={{PromptFoo}},
      year={2024},
      howpublished={\url{https://www.promptfoo.dev/}},
      note={Accessed: 12/06/2024}
}

@misc{llama_cpp_grammars,
      title={Llama.cpp Grammars Documentation},
      author={Ggerganov},
      year={2024},
      howpublished={\url{https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md}},
      note={Accessed: 2024}
}

@misc{backus_naur_form,
      title={Backus Naur form},
      author={{Wikipedia contributors}},
      year={2024},
      howpublished={\url{https://en.wiktionary.org/wiki/Backus-Naur_form}},
      note={Accessed: 2024}
}

@inproceedings{10.1145/3613905.3650756,
author = {Liu, Michael Xieyang and Liu, Frederick and Fiannaca, Alexander J. and Koo, Terry and Dixon, Lucas and Terry, Michael and Cai, Carrie J.},
title = {"We Need Structured Output": Towards User-centered Constraints on Large Language Model Output},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650756},
doi = {10.1145/3613905.3650756},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {10},
numpages = {9},
keywords = {Constrained generation, Large language models, Survey},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{long2024llms,
  title={LLMs Are Biased Towards Output Formats! Systematically Evaluating and Mitigating Output Format Bias of LLMs},
  author={Long, Do Xuan and Ngoc, Hai Nguyen and Sim, Tiviatis and Dao, Hieu and Joty, Shafiq and Kawaguchi, Kenji and Chen, Nancy F and Kan, Min-Yen},
  journal={arXiv preprint arXiv:2408.08656},
  year={2024}
}

@misc{langchain_text_splitters,
      title={Text Splitters - LangChain Documentation},
      author={{LangChain}},
      year={2024},
      howpublished={\url{https://python.langchain.com/docs/how_to/}},
      note={Accessed: 12/07/2024}
}

@misc{bruckhaus2024ragdoesworkenterprises,
      title={RAG Does Not Work for Enterprises}, 
      author={Tilmann Bruckhaus},
      year={2024},
      eprint={2406.04369},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2406.04369}, 
}

@misc{li2021embeddingbasedproductretrievaltaobao,
      title={Embedding-based Product Retrieval in Taobao Search}, 
      author={Sen Li and Fuyu Lv and Taiwei Jin and Guli Lin and Keping Yang and Xiaoyi Zeng and Xiao-Ming Wu and Qianli Ma},
      year={2021},
      eprint={2106.09297},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2106.09297}, 
}

@misc{instructorgithub,
    title={Instructor},
    author={instructor.ai},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/instructor-ai/instructor}
}

@misc{castillo2024say,
    title={Say What You Mean (Sometimes)},
    author={Dylan Castillo},
    year={2024},
    howpublished={Blog Post},
    url={https://dylancastillo.co/posts/say-what-you-mean-sometimes.html}
}

@misc{instructor2024structured,
    title={Should I be using structured outputs?},
    author={{Instructor.ai}},
    year={2024},
    howpublished={Blog Post},
    url={https://python.useinstructor.com/blog/2024/08/20/should-i-be-using-structured-outputs/}
}


@misc{castillo2024gemini,
    title={Structured Outputs with Gemini: A Practical Guide},
    author={Dylan Castillo},
    year={2024},
    howpublished={Blog Post},
    url={https://dylancastillo.co/posts/gemini-structured-outputs.html}
}


@misc{openai2024cookbookissue,
    title={OpenAI Cookbook: Change order of justification key in eval schema Issue},
    author={{OpenAI}},
    year={2024},
    howpublished={GitHub Pull Request},
    url={https://github.com/openai/openai-cookbook/pull/1619}
}


@misc{lmformatenforcergithub,
    title={LM Format Enforcer},
    author={{Noam Gat}},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/noamgat/lm-format-enforcer}
}

@misc{deeplearningai2024rag,
    title={Building and Evaluating Advanced RAG Applications},
    author={{DeepLearning.AI}},
    year={2024},
    howpublished={Website},
    url={https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/}
}

@article{10.1007/s10791-009-9096-x,
author = {Klampanos, Iraklis A.},
title = {Manning Christopher, Prabhakar Raghavan, Hinrich Sch\"{u}tze: Introduction to information retrieval: Cambridge University Press, Cambridge, 2008, 478 pp, Price 60, ISBN 97805218657515},
year = {2009},
issue_date = {Oct 2009},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {12},
number = {5},
issn = {1386-4564},
url = {https://doi.org/10.1007/s10791-009-9096-x},
doi = {10.1007/s10791-009-9096-x},
journal = {Inf. Retr.},
month = oct,
pages = {609–612},
numpages = {4}
}

@book{10.5555/1822502,
author = {Miller, Frederic P. and Vandome, Agnes F. and McBrewster, John},
title = {Levenshtein Distance: Information theory, Computer science, String (computer science), String metric, Damerau?Levenshtein distance, Spell checker, Hamming distance},
year = {2009},
isbn = {6130216904},
publisher = {Alpha Press}
}

@misc{google2024geminipricing,
      title={Gemini API Pricing}, 
      author={{Google}},
      year={2024},
      howpublished={Website},
      url={https://ai.google.dev/pricing#1_5pro},
      note={Pricing documentation for Gemini API models}
}

@misc{park2024iclrincontextlearningrepresentations,
      title={ICLR: In-Context Learning of Representations}, 
      author={Core Francisco Park and Andrew Lee and Ekdeep Singh Lubana and Yongyi Yang and Maya Okawa and Kento Nishi and Martin Wattenberg and Hidenori Tanaka},
      year={2024},
      eprint={2501.00070},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.00070}, 
}

@misc{jin2024ragcacheefficientknowledgecaching,
      title={RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation}, 
      author={Chao Jin and Zili Zhang and Xuanlin Jiang and Fangyue Liu and Xin Liu and Xuanzhe Liu and Xin Jin},
      year={2024},
      eprint={2404.12457},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2404.12457}, 
}

@misc{tran2021rerankmatchsemisupervisedlearningsemanticsoriented,
      title={ReRankMatch: Semi-Supervised Learning with Semantics-Oriented Similarity Representation}, 
      author={Trung Quang Tran and Mingu Kang and Daeyoung Kim},
      year={2021},
      eprint={2102.06328},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2102.06328}, 
}

@misc{sbert2024website,
    title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
    author={{SBERT}},
    year={2024},
    howpublished={Website},
    url={https://sbert.net/}
}


@misc{nvidia2024reranking,
    title={Enhancing RAG Pipelines with Re-ranking},
    author={{NVIDIA}},
    year={2024},
    howpublished={Website},
    url={https://developer.nvidia.com/blog/enhancing-rag-pipelines-with-re-ranking/}
}

@inproceedings{Lin2024, 
   title={Enhancing Relevance of Embedding-based Retrieval at Walmart},
   url={http://dx.doi.org/10.1145/3627673.3680047},
   DOI={10.1145/3627673.3680047},
   booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
   publisher={ACM},
   author={Lin, Juexin and Yadav, Sachin and Liu, Feng and Rossi, Nicholas and Suram, Praveen R. and Chembolu, Satya and Chandran, Prijith and Mohapatra, Hrushikesh and Lee, Tony and Magnani, Alessandro and Liao, Ciya},
   year={2024},
   month=oct}


@misc{jafari2021surveylocalitysensitivehashing,
      title={A Survey on Locality Sensitive Hashing Algorithms and their Applications}, 
      author={Omid Jafari and Preeti Maurya and Parth Nagarkar and Khandker Mushfiqul Islam and Chidambaram Crushev},
      year={2021},
      eprint={2102.08942},
      archivePrefix={arXiv},
      primaryClass={cs.DB},
      url={https://arxiv.org/abs/2102.08942}, 
}

@misc{oracle_hierarchical_indexes,
      title={Understanding Hierarchical Navigable Small World Indexes},
      author={{Oracle}},
      year={2024},
      howpublished={\url{https://docs.oracle.com/en/database/oracle/oracle-database/23/vecse/understand-hierarchical-navigable-small-world-indexes.html}},
      note={Accessed: 2024}
}


@misc{shorten2024structuredragjsonresponseformatting,
      title={StructuredRAG: JSON Response Formatting with Large Language Models}, 
      author={Connor Shorten and Charles Pierse and Thomas Benjamin Smith and Erika Cardenas and Akanksha Sharma and John Trengrove and Bob van Luijt},
      year={2024},
      eprint={2408.11061},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.11061}, 
}

@misc{cheng2024dateddatatracingknowledge,
      title={Dated Data: Tracing Knowledge Cutoffs in Large Language Models}, 
      author={Jeffrey Cheng and Marc Marone and Orion Weller and Dawn Lawrie and Daniel Khashabi and Benjamin Van Durme},
      year={2024},
      eprint={2403.12958},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.12958}, 
}

@misc{tang2024strucbenchlargelanguagemodels,
      title={Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?}, 
      author={Xiangru Tang and Yiming Zong and Jason Phang and Yilun Zhao and Wangchunshu Zhou and Arman Cohan and Mark Gerstein},
      year={2024},
      eprint={2309.08963},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.08963}, 
}

@misc{holtzman2020curiouscaseneuraltext,
      title={The Curious Case of Neural Text Degeneration}, 
      author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
      year={2020},
      eprint={1904.09751},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1904.09751}, 
}

@misc{white2024livebenchchallengingcontaminationfreellm,
      title={LiveBench: A Challenging, Contamination-Free LLM Benchmark}, 
      author={Colin White and Samuel Dooley and Manley Roberts and Arka Pal and Ben Feuer and Siddhartha Jain and Ravid Shwartz-Ziv and Neel Jain and Khalid Saifullah and Siddartha Naidu and Chinmay Hegde and Yann LeCun and Tom Goldstein and Willie Neiswanger and Micah Goldblum},
      year={2024},
      eprint={2406.19314},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.19314}, 
}

@misc{wang2019gluemultitaskbenchmarkanalysis,
      title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding}, 
      author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2019},
      eprint={1804.07461},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1804.07461}, 
}

@article{nangia2019superglue,
title = "SuperGLUE: A stickier benchmark for general-purpose language understanding systems",
year = "2019",
author = "Alex Wang and Yada Pruksachatkun and Nikita Nangia and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Bowman, {Samuel R.}",
language = "English (US)",
volume = "32",
journal = "Advances in Neural Information Processing Systems",
issn = "1049-5258",
publisher = "Neural information processing systems foundation",
}

@misc{srivastava2023imitationgamequantifyingextrapolating,
      title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models}, 
      author={Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adrià Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlmüller and Andrew Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karakaş and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartłomiej Bojanowski and Batuhan Özyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and César Ferri Ramírez and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Chris Waites and Christian Voigt and Christopher D. Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Moseguí González and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodola and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A. Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Martínez-Plumed and Francesca Happé and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germán Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Wang and Gonzalo Jaimovitch-López and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Shevlin and Hinrich Schütze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fernández Fisac and James B. Simon and James Koppel and James Zheng and James Zou and Jan Kocoń and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and Jörg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh D. Dhole and Kevin Gimpel and Kevin Omondi and Kory Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros Colón and Luke Metz and Lütfi Kerem Şenel and Maarten Bosma and Maarten Sap and Maartje ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramírez Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L. Leavitt and Matthias Hagen and Mátyás Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael A. Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Michał Swędrowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan A. Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Miłkowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Raphaël Millière and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan LeBras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Ruslan Salakhutdinov and Ryan Chi and Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel S. Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima and Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven T. Piantadosi and Stuart M. Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsu Hashimoto and Te-Lin Wu and Théo Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Ramasesh and Vinay Uday Prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Yiding Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
      year={2023},
      eprint={2206.04615},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2206.04615}, 
}

@book{kamath2024large,
  title={Large Language Models: A Deep Dive: Bridging Theory and Practice},
  author={Kamath, U. and Keenan, K. and Somers, G. and Sorenson, S.},
  isbn={9783031656477},
  url={https://books.google.com.br/books?id=kDobEQAAQBAJ},
  year={2024},
  publisher={Springer Nature Switzerland}
}

@misc{2021truthfulqa,
      title={TruthfulQA: Measuring How Models Mimic Human Falsehoods}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.07958}, 
}

@misc{liang2023holisticevaluationlanguagemodels,
      title={Holistic Evaluation of Language Models}, 
      author={Percy Liang and Rishi Bommasani and Tony Lee and Dimitris Tsipras and Dilara Soylu and Michihiro Yasunaga and Yian Zhang and Deepak Narayanan and Yuhuai Wu and Ananya Kumar and Benjamin Newman and Binhang Yuan and Bobby Yan and Ce Zhang and Christian Cosgrove and Christopher D. Manning and Christopher Ré and Diana Acosta-Navas and Drew A. Hudson and Eric Zelikman and Esin Durmus and Faisal Ladhak and Frieda Rong and Hongyu Ren and Huaxiu Yao and Jue Wang and Keshav Santhanam and Laurel Orr and Lucia Zheng and Mert Yuksekgonul and Mirac Suzgun and Nathan Kim and Neel Guha and Niladri Chatterji and Omar Khattab and Peter Henderson and Qian Huang and Ryan Chi and Sang Michael Xie and Shibani Santurkar and Surya Ganguli and Tatsunori Hashimoto and Thomas Icard and Tianyi Zhang and Vishrav Chaudhary and William Wang and Xuechen Li and Yifan Mai and Yuhui Zhang and Yuta Koreeda},
      year={2023},
      eprint={2211.09110},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2211.09110}, 
}

@misc{hendrycks2021measuringmassivemultitasklanguage,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}

@misc{chen2021evaluatinglargelanguagemodels,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2107.03374}, 
}

@misc{chiang2024chatbotarenaopenplatform,
      title={Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference}, 
      author={Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael Jordan and Joseph E. Gonzalez and Ion Stoica},
      year={2024},
      eprint={2403.04132},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2403.04132}, 
}

@misc{openllmleaderboard2024,
      title={Open LLM Leaderboard},
      author={HuggingFace},
      year={2024},
      howpublished={HuggingFace Spaces},
      url={https://huggingface.co/spaces/open-llm-leaderboard/blog},
}

@misc{dubois2024lengthcontrolledalpacaevalsimpleway,
      title={Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators}, 
      author={Yann Dubois and Balázs Galambosi and Percy Liang and Tatsunori B. Hashimoto},
      year={2024},
      eprint={2404.04475},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.04475}, 
}

@misc{zheng2023judgingllmasajudgemtbenchchatbot,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.05685}, 
}

@misc{arcprize2024,
      title={Abstraction and Reasoning Challenge},
      author={Francois Chollet},
      year={2024},
      howpublished={ARC Prize Website},
      url={https://arcprize.org/},
}

@misc{arcprizeresults2024,
      title={ARC Prize 2024 Results},
      author={Francois Chollet},
      year={12/08/2024},
      howpublished={ARC Prize Website},
      url={https://arcprize.org/2024-results},
}

@book{build-llms-from-scratch-book,
  author       = {Sebastian Raschka},
  title        = {Build A Large Language Model (From Scratch)},
  publisher    = {Manning},
  year         = {2024},
  isbn         = {978-1633437166},
  url          = {https://www.manning.com/books/build-a-large-language-model-from-scratch},
  github       = {https://github.com/rasbt/LLMs-from-scratch}
}

@misc{zebralogic2024,
    title={ZebraLogic: Benchmarking the Logical Reasoning Ability of Language Models},
    author={Bill Yuchen Lin and Ronan Le Bras and Yejin Choi},
    url={https://huggingface.co/spaces/allenai/ZebraLogic},
    year={2024}
}

@article{brailsford1999constraint,
title = {Constraint satisfaction problems: Algorithms and applications},
journal = {European Journal of Operational Research},
volume = {119},
number = {3},
pages = {557-581},
year = {1999},
issn = {0377-2217},
doi = {https://doi.org/10.1016/S0377-2217(98)00364-6},
url = {https://www.sciencedirect.com/science/article/pii/S0377221798003646},
author = {Sally C. Brailsford and Chris N. Potts and Barbara M. Smith}
}

@misc{vivien2024regex,
title={Fast, High-Fidelity LLM Decoding with Regex Constraints},
url={https://vivien000.github.io/blog/journal/llm-decoding-with-regex-constraints.html},
journal={Unsupervised Thoughts (blog)},
author={Tran-Thien, Vivien},
year={2024}
}

@misc{willard2023efficientguidedgenerationlarge,
      title={Efficient Guided Generation for Large Language Models}, 
      author={Brandon T. Willard and Rémi Louf},
      year={2023},
      eprint={2307.09702},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09702}, 
}

@misc{smollm2024model,
    title={SmolLM2-360M-Instruct},
    author={HuggingFace SmolLM2-360M-Instruct},
    year={2024},
    url={https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct},
    note={360M parameter instruction-tuned language model, distilled for efficient deployment}
}

@misc{promptfoo2024,
    title={promptfoo: LLM Testing and Evaluation Framework},
    author={promptfoo},
    year={2024},
    url={https://www.promptfoo.dev/},
    note={Open source framework for testing and evaluating LLM prompts}
}

@misc{scikit2024evaluation,
    title={Model evaluation: quantifying the quality of predictions},
    author={{scikit-learn developers}},
    year={2024},
    howpublished={Website},
    url={https://scikit-learn.org/1.5/modules/model_evaluation.html}
}



@misc{vidgen2024introducingv05aisafety,
      title={Introducing v0.5 of the AI Safety Benchmark from MLCommons}, 
      author={Bertie Vidgen and Adarsh Agrawal and Ahmed M. Ahmed and Victor Akinwande and Namir Al-Nuaimi and Najla Alfaraj and Elie Alhajjar and Lora Aroyo and Trupti Bavalatti and Max Bartolo and Borhane Blili-Hamelin and Kurt Bollacker and Rishi Bomassani and Marisa Ferrara Boston and Siméon Campos and Kal Chakra and Canyu Chen and Cody Coleman and Zacharie Delpierre Coudert and Leon Derczynski and Debojyoti Dutta and Ian Eisenberg and James Ezick and Heather Frase and Brian Fuller and Ram Gandikota and Agasthya Gangavarapu and Ananya Gangavarapu and James Gealy and Rajat Ghosh and James Goel and Usman Gohar and Sujata Goswami and Scott A. Hale and Wiebke Hutiri and Joseph Marvin Imperial and Surgan Jandial and Nick Judd and Felix Juefei-Xu and Foutse Khomh and Bhavya Kailkhura and Hannah Rose Kirk and Kevin Klyman and Chris Knotz and Michael Kuchnik and Shachi H. Kumar and Srijan Kumar and Chris Lengerich and Bo Li and Zeyi Liao and Eileen Peters Long and Victor Lu and Sarah Luger and Yifan Mai and Priyanka Mary Mammen and Kelvin Manyeki and Sean McGregor and Virendra Mehta and Shafee Mohammed and Emanuel Moss and Lama Nachman and Dinesh Jinenhally Naganna and Amin Nikanjam and Besmira Nushi and Luis Oala and Iftach Orr and Alicia Parrish and Cigdem Patlak and William Pietri and Forough Poursabzi-Sangdeh and Eleonora Presani and Fabrizio Puletti and Paul Röttger and Saurav Sahay and Tim Santos and Nino Scherrer and Alice Schoenauer Sebag and Patrick Schramowski and Abolfazl Shahbazi and Vin Sharma and Xudong Shen and Vamsi Sistla and Leonard Tang and Davide Testuggine and Vithursan Thangarasa and Elizabeth Anne Watkins and Rebecca Weiss and Chris Welty and Tyler Wilbers and Adina Williams and Carole-Jean Wu and Poonam Yadav and Xianjun Yang and Yi Zeng and Wenhui Zhang and Fedor Zhdanov and Jiacheng Zhu and Percy Liang and Peter Mattson and Joaquin Vanschoren},
      year={2024},
      eprint={2404.12241},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.12241}, 
}

@misc{kim2024evaluatinglanguagemodelssynthetic,
      title={Evaluating Language Models as Synthetic Data Generators}, 
      author={Seungone Kim and Juyoung Suk and Xiang Yue and Vijay Viswanathan and Seongyun Lee and Yizhong Wang and Kiril Gashteovski and Carolin Lawrence and Sean Welleck and Graham Neubig},
      year={2024},
      eprint={2412.03679},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.03679}, 
}

@misc{wu2024metarewardinglanguagemodelsselfimproving,
      title={Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge}, 
      author={Tianhao Wu and Weizhe Yuan and Olga Golovneva and Jing Xu and Yuandong Tian and Jiantao Jiao and Jason Weston and Sainbayar Sukhbaatar},
      year={2024},
      eprint={2407.19594},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.19594}, 
}

@misc{chollet2024tweet,
    title={Chollet on ARC-AGI-1},
    author={François Chollet},
    year={2025},
    howpublished={Tweet},
    url={https://x.com/fchollet/status/1874877373629493548},
    note={Accessed: 04/01/2025}
}

@misc{xie2024ordermattershallucinationreasoning,
      title={Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models}, 
      author={Zikai Xie},
      year={2024},
      eprint={2408.05093},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2408.05093}, 
}

@misc{smollm2024,
    title={SmoLLM: A Small Language Model Distilled from a Larger Language Model for Task-specific Applications},
    author={HuggingFace SmolLM2},
    year={2024},
    url={https://huggingface.co/blog/smollm},
    note={Blog post describing techniques for distilling smaller, task-specific language models}
}

@article{Yin2024SelfAugmentedPO,
  title={Self-Augmented Preference Optimization: Off-Policy Paradigms for Language Model Alignment},
  author={Yueqin Yin and Zhendong Wang and Yujia Xie and Weizhu Chen and Mingyuan Zhou},
  journal={ArXiv},
  year={2024},
  volume={abs/2405.20830},
  url={https://api.semanticscholar.org/CorpusID:270199610}
}


@misc{bai2022constitutionalaiharmlessnessai,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2212.08073}, 
}

@misc{dong2024selfboostinglargelanguagemodels,
      title={Self-Boosting Large Language Models with Synthetic Preference Data}, 
      author={Qingxiu Dong and Li Dong and Xingxing Zhang and Zhifang Sui and Furu Wei},
      year={2024},
      eprint={2410.06961},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.06961}, 
}

@misc{vinge1993singularity,
    title={The Coming Technological Singularity: How to Survive in the Post-Human Era},
    author={Vernor Vinge},
    year={1993},
    howpublished={VISION-21 Symposium},
    url={https://edoras.sdsu.edu/~vinge/misc/singularity.html},
}


@techreport{tonerrodgers2024aidiscovery,
    title={Artificial Intelligence, Scientific Discovery, and Product Innovation},
    author={Toner-Rodgers, Aidan},
    year={2024},
    url={https://aidantr.github.io/files/AI_innovation.pdf}
}


@misc{askell2024alignmentfaking,
      title={Alignment Faking in Large Language Models}, 
      author={Amanda Askell and Jan Brauner and Adrian Colyer and Benjamin Cullen and David Duvenaud and Richard Ngo and Azalia Mirhoseini and Catherine Olsson and Sam Ringer and Liam Skirvin and Jess Smith and Dawn Song and William Saunders and Steinhardt, Jacob},
      year={2024a},
      publisher={Anthropic}}

@misc{askell2024alignmentfakingreviews,
      title={Alignment Faking in Large Language Models: Reviews}, 
      author={Amanda Askell and Jan Brauner and Adrian Colyer and Benjamin Cullen and David Duvenaud and Richard Ngo and Azalia Mirhoseini and Catherine Olsson and Sam Ringer and Liam Skirvin and Jess Smith and Dawn Song and William Saunders and Steinhardt, Jacob},
      year={2024b},
      publisher={Anthropic},
      url={https://assets.anthropic.com/m/24c8d0a3a7d0a1f1/original/Alignment-Faking-in-Large-Language-Models-reviews.pdf}
}

@misc{ggerganov2023llamacppdiscussion,
    title={Quantization of LLaMA models - Discussion},
    author={Georgi Gerganov and others},
    year={2023},
    howpublished={GitHub Discussion},
    url={https://github.com/ggerganov/llama.cpp/discussions/205},
    note={Discussion thread about quantization techniques and tradeoffs in llama.cpp}
}


@misc{lmstudio2024,
    title={LM Studio - Discover, Download, and Run Local LLMs},
    author={{LM Studio}},
    year={2024},
    howpublished={Website},
    url={https://lmstudio.ai/},
    note={Desktop application for discovering, downloading and running local language models}
}


@misc{mozilla2024llamafile,
    title={llamafile: Distribute and run LLMs with a single file},
    author={{Mozilla Ocho}},
    year={2024},
    howpublished={GitHub Repository}, 
    url={https://github.com/Mozilla-Ocho/llamafile},
    note={Tool for packaging and distributing LLMs as self-contained executables}
}


@misc{huggingface2024llamafilemodels,
    title={Llamafile Models on HuggingFace},
    author={{HuggingFace}},
    year={2024x},
    howpublished={Online Repository},
    url={https://huggingface.co/models?library=llamafile},
    note={Collection of models compatible with Mozilla's llamafile format}
}


@misc{huggingface2024chattemplating,
    title={Chat Templating Documentation},
    author={{HuggingFace}},
    year={2024y},
    howpublished={Online Documentation},
    url={https://huggingface.co/docs/transformers/main/en/chat_templating},
    note={Documentation on chat templates and formatting for language models}
}

@misc{betlen2024llamacpppython,
    title={llama-cpp-python},
    author={Andrei Betlen and contributors},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/abetlen/llama-cpp-python},
    note={Python bindings for llama.cpp library enabling high-performance inference of LLaMA models}
}

@misc{meta2024llama2chat70b,
    title={Llama-2-70b-chat-hf},
    author={{Meta AI}},
    year={2024c},
    howpublished={HuggingFace Model},
    url={https://huggingface.co/meta-llama/Llama-2-70b-chat-hf},
    note={70 billion parameter chat model from Meta's Llama 2 family}
}


@misc{deshpande2024glidergradingllminteractions,
      title={GLIDER: Grading LLM Interactions and Decisions using Explainable Ranking}, 
      author={Darshan Deshpande and Selvan Sunitha Ravi and Sky CH-Wang and Bartosz Mielczarek and Anand Kannappan and Rebecca Qian},
      year={2024},
      eprint={2412.14140},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.14140}, 
}

@misc{unsloth2024llama3,
    title={Llama-3.3-70B-Instruct-GGUF},
    author={{Unsloth}},
    year={2024},
    howpublished={HuggingFace Model},
    url={https://huggingface.co/unsloth/Llama-3.3-70B-Instruct-GGUF},
    note={GGUF quantized version of Meta's Llama 3.3 70B instruction-tuned model}
}


@misc{nvidia2024logitsprocessorzoo,
    title={Logits Processor Zoo},
    author={{NVIDIA}},
    year={2024a},
    howpublished={GitHub Repository},
    url={https://github.com/NVIDIA/logits-processor-zoo},
    note={Collection of logits processors for controlling language model generation}
}


@misc{guidance2024repo,
    title={Guidance: Language Model Programming},
    author={{Guidance AI}},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/guidance-ai/guidance},
    note={Framework for programming language models with structured templating and control flow}
}


@misc{alnajjar2024toxigen,
    title={ToxiGen Dataset},
    author={Alnajjar, Khalid and others},
    year={2024},
    howpublished={Papers with Code Dataset},
    url={https://paperswithcode.com/dataset/toxigen},
    note={Dataset for evaluating and mitigating toxic language generation in language models}
}

@misc{sarmah2024choosethresholdevaluationmetric,
      title={How to Choose a Threshold for an Evaluation Metric for Large Language Models}, 
      author={Bhaskarjit Sarmah and Mingshu Li and Jingrao Lyu and Sebastian Frank and Nathalia Castellanos and Stefano Pasquali and Dhagash Mehta},
      year={2024},
      eprint={2412.12148},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2412.12148}, 
}

@misc{salesforce2024wikitext,
    title={WikiText Dataset},
    author={{Salesforce}},
    year={2024},
    howpublished={HuggingFace Dataset},
    url={https://huggingface.co/datasets/Salesforce/wikitext},
    note={Large-scale dataset derived from verified Good and Featured articles on Wikipedia}
}

@misc{wang20241bitaiinfra11,
      title={1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs}, 
      author={Jinheng Wang and Hansong Zhou and Ting Song and Shaoguang Mao and Shuming Ma and Hongyu Wang and Yan Xia and Furu Wei},
      year={2024},
      eprint={2410.16144},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.16144}, 
}

@misc{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.11401}, 
}

@misc{deepseek2024v3,
    title={DeepSeek-V3 Technical Report},
    author={DeepSeek},
    year={2024},
    howpublished={Technical Report},
    url={https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf}
}

@misc{docling2024github,
    title={DocLing: A Document-Level Linguistic Annotation Framework},
    author={{IBM Research}},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/DS4SD/docling},
    note={Framework for document-level linguistic annotation and analysis}
}

@misc{unstructured2024github,
    title={Unstructured: Open Source Libraries for Pre-Processing Documents},
    author={{Unstructured.io}},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/Unstructured-IO/unstructured}
}

@misc{mendable2024firecrawl,
    title={FireCrawl: A Fast and Efficient Web Crawler for LLM Training Data},
    author={{Mendable AI}},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/mendableai/firecrawl},
    note={High-performance web crawler optimized for collecting LLM training data}
}


@misc{microsoft2024markitdown,
    title={MarkItDown: Structured Generation with Large Language Models},
    author={{Microsoft}},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/microsoft/markitdown},
    note={Framework for structured text generation using LLMs}
}


@misc{merrill2024,
    title={CHIEF INVESTMENT OFFICER CAPITAL MARKET OUTLOOK},
    author={{Merrill Lynch}},
    year={2024},
    howpublished={CIO Weekly Letter},
    url={https://olui2.fs.ml.com/publish/content/application/pdf/gwmol/me-cio-weekly-letter.pdf}
}


@misc{a16z2024llmflation,
    title={LLMflation: Understanding and Mitigating LLM Inference Cost},
    author={{Andreessen Horowitz}},
    year={2024},
    howpublished={Blog Post},
    url={https://a16z.com/llmflation-llm-inference-cost/},
    note={Analysis of LLM inference costs and strategies for optimization}
}


@misc{huggingface2024quantization,
    title={GGUF Quantization Types},
    author={{HuggingFace}},
    year={2024w},
    howpublished={Online Documentation},
    url={https://huggingface.co/docs/hub/gguf#quantization-types},
    note={Documentation on different quantization types available for GGUF models}
}


@misc{ggerganov2024llamacppgrammars,
    title={llama.cpp Grammars Documentation},
    author={Georgi Gerganov and contributors},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md},
    note={Documentation on using grammars for constrained text generation in llama.cpp}
}


@misc{langchain2024outlines,
    title={Outlines Integration Documentation},
    author={LangChain},
    year={2024b},
    howpublished={Online Documentation},
    url={https://python.langchain.com/docs/integrations/chat/outlines/},
    note={Documentation on integrating Outlines library with LangChain for structured generation}
}


@misc{ggerganov2024llamacpp,
    title={llama.cpp},
    author={Georgi Gerganov and contributors},
    year={2024a},
    howpublished={GitHub Repository},
    url={https://github.com/ggerganov/llama.cpp},
    note={High-performance inference of LLaMA models in pure C/C++}
}



@misc{ibm2024ggufversusggml,
    title={GGUF vs GGML: What's the Difference?},
    author={{IBM Think}},
    year={2024},
    publisher={IBM},
    url={https://www.ibm.com/think/topics/gguf-versus-ggml},
    note={Comparison of GGUF and GGML model formats}
}

@misc{huggingface2024ggufmodels,
    title={GGUF Models on HuggingFace},
    author={{HuggingFace}},
    year={2024x},
    howpublished={Online Repository},
    url={https://huggingface.co/models?search=gguf},
    note={Collection of models in GGUF format for efficient local inference}
}

@misc{ggerganov2024ggufspec,
    title={GGUF File Format Specification},
    author={Georgi Gerganov and contributors},
    year={2024b},
    howpublished={GitHub Repository},
    url={https://github.com/ggerganov/ggml/blob/master/docs/gguf.md},
    note={Technical specification of the GGUF file format for efficient model storage and inference}
}





@misc{singh2024globalmmluunderstandingaddressing,
      title={Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation}, 
      author={Shivalika Singh and Angelika Romanou and Clémentine Fourrier and David I. Adelani and Jian Gang Ngui and Daniel Vila-Suero and Peerat Limkonchotiwat and Kelly Marchisio and Wei Qi Leong and Yosephine Susanto and Raymond Ng and Shayne Longpre and Wei-Yin Ko and Madeline Smith and Antoine Bosselut and Alice Oh and Andre F. T. Martins and Leshem Choshen and Daphne Ippolito and Enzo Ferrante and Marzieh Fadaee and Beyza Ermis and Sara Hooker},
      year={2024},
      eprint={2412.03304},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.03304}, 
}

@book{kimothi2024simpleguiderag,
    title={A Simple Guide to Retrieval Augmented Generation},
    author={Kimothi, Abhinav},
    year={2024},
    publisher={Manning Publications},
    isbn={9781633435858},
    note={Manning Early Access Program (MEAP)},
    url={https://www.manning.com/books/a-simple-guide-to-retrieval-augmented-generation}
}


@book{hands-on-llms-book,
  author       = {Jay Alammar and Maarten Grootendorst},
  title        = {Hands-On Large Language Models},
  publisher    = {O'Reilly},
  year         = {2024},
  isbn         = {978-1098150969},
  url          = {https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/},
  github       = {https://github.com/HandsOnLLM/Hands-On-Large-Language-Models}
}

@misc{diamant2024ragtechniques,
    title={RAG Techniques},
    author={Nir Diamant},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/NirDiamant/RAG_Techniques},
    note={Collection of advanced RAG techniques and implementation patterns}
}


@misc{athinaai2024ragcookbooks,
    title={RAG Cookbooks},
    author={{AthinaAI}},
    year={2024},
    howpublished={GitHub Repository},
    url={https://github.com/athina-ai/rag-cookbooks},
    note={Collection of recipes and best practices for building RAG applications}
}

@misc{tharsistpsouza2024tamingllms,
  author = {Tharsis T. P. Souza},
  title = {Taming LLMs: A Practical Guide to LLM Pitfalls with Open Source Software},
  year = {2024},
  chapter = {The Evals Gap},
  journal = {GitHub repository},
  url = {https://github.com/souzatharsis/tamingLLM}
}

@book{huyen2024aiengineering,
    title={AI Engineering},
    author={Huyen, Chip},
    year={2024},
    publisher={O'Reilly Media, Inc.},
    month={December},
    isbn={9781098129095},
    url={https://www.oreilly.com/library/view/ai-engineering/9781098129095/}
}

@misc{feng2024analyzingunderstandinglimitationsdpo,
      title={Towards Analyzing and Understanding the Limitations of DPO: A Theoretical Perspective}, 
      author={Duanyu Feng and Bowen Qin and Chen Huang and Zheng Zhang and Wenqiang Lei},
      year={2024},
      eprint={2404.04626},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.04626}, 
}

@misc{hou2024doesrlhfscaleexploring,
      title={Does RLHF Scale? Exploring the Impacts From Data, Model, and Method}, 
      author={Zhenyu Hou and Pengfan Du and Yilin Niu and Zhengxiao Du and Aohan Zeng and Xiao Liu and Minlie Huang and Hongning Wang and Jie Tang and Yuxiao Dong},
      year={2024},
      eprint={2412.06000},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.06000}, 
}

@misc{szep2024practicalguidefinetuninglanguage,
      title={A Practical Guide to Fine-tuning Language Models with Limited Data}, 
      author={Márton Szép and Daniel Rueckert and Rüdiger von Eisenhart-Rothe and Florian Hinterwimmer},
      year={2024},
      eprint={2411.09539},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.09539}, 
}

@misc{kazdan2024collapsethriveperilspromises,
      title={Collapse or Thrive? Perils and Promises of Synthetic Data in a Self-Generating World}, 
      author={Joshua Kazdan and Rylan Schaeffer and Apratim Dey and Matthias Gerstgrasser and Rafael Rafailov and David L. Donoho and Sanmi Koyejo},
      year={2024},
      eprint={2410.16713},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.16713}, 
}

@misc{mlcommons2024lead,
    title={MLCommons AI Illuminate Benchmarks},
    author={MLCommons},
    year={2024},
    url={https://ailuminate.mlcommons.org/benchmarks/},
    note={A collection of standardized benchmarks for evaluating AI systems}
}


@misc{ultrafeedback2024,
    title={UltraFeedback Binarized Dataset},
    author={HuggingFace H4},
    year={2024a},
    url={https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized},
    note={A dataset of binary preference data for training language models}
}


@misc{ultrafeedback2024z,
    title={UltraFeedback Binarized Dataset},
    author={HuggingFace H4},
    year={2024z},
    url={https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized},
    note={A dataset of binary preference data for training language models}
}

@misc{huggingfaceh42024,
    title={HuggingFace H4},
    author={HuggingFace H4},
    year={2024b},
    url={https://huggingface.co/HuggingFaceH4},
    note={HuggingFace H4}
}

@misc{evalstamingllms2024,
    title={TamingLLMs: A Framework for Evaluating and Aligning Language Models},
    chapter={The Evals Gap},
    author={Tharsis T. P. Souza},
    year={2024},
    url={https://www.souzatharsis.com/tamingLLMs/notebooks/evals.html}
}

@misc{evalstamingllms2024b,
    title={TamingLLMs: A Framework for Evaluating and Aligning Language Models},
    chapter={Wrestling with Structured Output},
    author={Tharsis T. P. Souza},
    year={2024},
    url={https://www.souzatharsis.com/tamingLLMs/notebooks/structured_output.html}
}


@misc{huang2022largelanguagemodelsselfimprove,
      title={Large Language Models Can Self-Improve}, 
      author={Jiaxin Huang and Shixiang Shane Gu and Le Hou and Yuexin Wu and Xuezhi Wang and Hongkun Yu and Jiawei Han},
      year={2022},
      eprint={2210.11610},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.11610}, 
}


@misc{long2024llmsdrivensyntheticdatageneration,
      title={On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey}, 
      author={Lin Long and Rui Wang and Ruixuan Xiao and Junbo Zhao and Xiao Ding and Gang Chen and Haobo Wang},
      year={2024},
      eprint={2406.15126},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.15126}, 
}

@misc{hao2024syntheticdataaichallenges,
      title={Synthetic Data in AI: Challenges, Applications, and Ethical Implications}, 
      author={Shuang Hao and Wenfeng Han and Tao Jiang and Yiping Li and Haonan Wu and Chunlin Zhong and Zhangjun Zhou and He Tang},
      year={2024},
      eprint={2401.01629},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2401.01629}, 
}

@misc{chen2024humansllmsjudgestudy,
      title={Humans or LLMs as the Judge? A Study on Judgement Biases}, 
      author={Guiming Hardy Chen and Shunian Chen and Ziche Liu and Feng Jiang and Benyou Wang},
      year={2024},
      eprint={2402.10669},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.10669}, 
}

@misc{meta-llama2024,
    title={Meta-Llama},
    author={Meta},
    year={2024},
    url={https://huggingface.co/meta-llama},
    note={Meta-Llama}
}

@misc{qwen2024,
    title={Qwen},
    author={Qwen},
    year={2024},
    url={https://huggingface.co/Qwen},
    note={Qwen}
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Meta AI},
      year={2024c},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{hf2024scalingtesttime,
    title={Scaling Test Time Compute},
    author={HuggingFace},
    year={2024v},
    url={https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute},
    note={Accessed: 2024}
}

@misc{hf2024ultrachat200k,
    title={UltraChat-200K Dataset},
    author={HuggingFace},
    year={2024u},
    url={https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k},
    note={Accessed: 2024}
}


@misc{zhao2024loraland310finetuned,
      title={LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report}, 
      author={Justin Zhao and Timothy Wang and Wael Abid and Geoffrey Angus and Arnav Garg and Jeffery Kinnison and Alex Sherstinsky and Piero Molino and Travis Addair and Devvret Rishi},
      year={2024},
      eprint={2405.00732},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.00732}, 
}

@misc{qwen2024moe,
    title={Qwen-MoE: Serving Large Language Models with Mixture of Experts},
    author={Qwen Team},
    year={2024},
    url={https://qwenlm.github.io/blog/qwen-moe/},
    note={Accessed: 2024}
}



@misc{qwen25instruct2024,
    title={Qwen2.5-1.5B-Instruct},
    author={Qwen},
    year={2024b},
    url={https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct},
    note={Accessed: December 22, 2024}
}




@misc{qwen2024qwen25technicalreport,
      title={Qwen2.5 Technical Report}, 
      author={Qwen and : and An Yang and Baosong Yang and Beichen Zhang and Binyuan Hui and Bo Zheng and Bowen Yu and Chengyuan Li and Dayiheng Liu and Fei Huang and Haoran Wei and Huan Lin and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Yang and Jiaxi Yang and Jingren Zhou and Junyang Lin and Kai Dang and Keming Lu and Keqin Bao and Kexin Yang and Le Yu and Mei Li and Mingfeng Xue and Pei Zhang and Qin Zhu and Rui Men and Runji Lin and Tianhao Li and Tingyu Xia and Xingzhang Ren and Xuancheng Ren and Yang Fan and Yang Su and Yichang Zhang and Yu Wan and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zihan Qiu},
      year={2024},
      eprint={2412.15115},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.15115}, 
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@misc{zephyr2024,
    title={Zephyr},
    author={HuggingFace},
    year={2024},
    url={https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha},
    note={Zephyr}
}

@misc{dubey2024llama3herdmodels,
  title =         {The Llama 3 Herd of Models},
  author =        {Llama Team, AI @ Meta},
  year =          {2024},
  eprint =        {2407.21783},
  archivePrefix = {arXiv},
  primaryClass =  {cs.AI},
  url =           {https://arxiv.org/abs/2407.21783}
}

@misc{hong2024orpomonolithicpreferenceoptimization,
      title={ORPO: Monolithic Preference Optimization without Reference Model}, 
      author={Jiwoo Hong and Noah Lee and James Thorne},
      year={2024},
      eprint={2403.07691},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.07691}, 
}


@misc{rafailov2024directpreferenceoptimizationlanguage,
      title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, 
      author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
      year={2024},
      eprint={2305.18290},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.18290}, 
}

@techreport{ukgov2024airegulation24,
      title={AI Regulation: A Pro-Innovation Approach}, 
      author={{UK Government}},
      year={2024},
      institution={Department for Science, Innovation and Technology},
      type={White Paper},
      url={https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper},
}


@inproceedings{10.1145/3589334.3645481,
author = {Zhou, Yujia and Liu, Zheng and Jin, Jiajie and Nie, Jian-Yun and Dou, Zhicheng},
title = {Metacognitive Retrieval-Augmented Large Language Models},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645481},
doi = {10.1145/3589334.3645481},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1453-1463},
numpages = {11},
keywords = {llms, metacognition, retrieval-augmented generation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@misc{tan2024htmlraghtmlbetterplain,
      title={HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems}, 
      author={Jiejun Tan and Zhicheng Dou and Wen Wang and Mang Wang and Weipeng Chen and Ji-Rong Wen},
      year={2024},
      eprint={2411.02959},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2411.02959}, 
}

@misc{anthropic2024contextualretrieval,
      title={Introducing Contextual Retrieval}, 
      author={{Anthropic}},
      year={2024a},
      month={09},
      url={https://www.anthropic.com/news/contextual-retrieval}
}


@article{zhou2024larger,
author = {Zhou, Lexin and Schellaert, Wout and Plumed, Fernando and Moros-Daval, Yael and Ferri, Cesar and Hernández-Orallo, Jose},
year = {2024},
month = {09},
pages = {61-68},
title = {Larger and more instructable language models become less reliable},
volume = {634},
journal = {Nature},
doi = {10.1038/s41586-024-07930-y}
}

@inproceedings{amayuelas-etal-2024-knowledge,
    title = "Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models",
    author = "Amayuelas, Alfonso  and
      Wong, Kyle  and
      Pan, Liangming  and
      Chen, Wenhu  and
      Wang, William Yang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.383",
    doi = "10.18653/v1/2024.findings-acl.383",
    pages = "6416--6432",

}

@inproceedings{
kotha2024understanding,
title={Understanding Catastrophic Forgetting in Language Models via Implicit Inference},
author={Suhas Kotha and Jacob Mitchell Springer and Aditi Raghunathan},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=VrHiF2hsrm}
}



@inproceedings{ni-etal-2024-llms,
    title = "When Do {LLM}s Need Retrieval Augmentation? Mitigating {LLM}s{'} Overconfidence Helps Retrieval Augmentation",
    author = "Ni, Shiyu  and
      Bi, Keping  and
      Guo, Jiafeng  and
      Cheng, Xueqi",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2024",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-acl.675",
    doi = "10.18653/v1/2024.findings-acl.675",
    pages = "11375--11388",
}

@misc{meta2024llamaguard,
      title={LlamaGuard: LLM-based Input-Output Safeguard for Human-AI Conversations}, 
      author={Meta-AI},
      year={2024},
      howpublished={Meta AI Research Publications},
      url={https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/},
}



@misc{touvron2023llama2openfoundation,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      eprint={2307.09288},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.09288}, 
}

@misc{bai2022traininghelpfulharmlessassistant,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      eprint={2204.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2204.05862}, 
}

@misc{hu2021loralowrankadaptationlarge,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2106.09685}, 
}

@misc{dettmers2023qloraefficientfinetuningquantized,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      eprint={2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.14314}, 
}

@misc{xu2024dposuperiorppollm,
      title={Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study}, 
      author={Shusheng Xu and Wei Fu and Jiaxuan Gao and Wenjie Ye and Weilin Liu and Zhiyu Mei and Guangju Wang and Chao Yu and Yi Wu},
      year={2024},
      eprint={2404.10719},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.10719}, 
}

@misc{huggingface2024rlhf,
    title={RLHF},
    author={HuggingFace},
    year={2024c},
    url={https://huggingface.co/blog/rlhf},
    note={RLHF}
}

@misc{schulman2017proximalpolicyoptimizationalgorithms,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      eprint={1707.06347},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1707.06347}, 
}

@misc{neurips2023awards,
    title={Announcing the NeurIPS 2023 Paper Awards},
    author={NeurIPS Blog},
    year={2023},
    url={https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/},
    note={NeurIPS 2023 Awards}
}


@techreport{finra2024llmguidance24,
      title={Artificial Intelligence, Including Large Language Models and Generative AI}, 
      author={{Financial Industry Regulatory Authority}},
      year={2024},
      institution={FINRA},
      type={Regulatory Notice},
      number={24-09},
      url={https://www.finra.org/rules-guidance/notices/24-09},
}



@misc{huggingface2024trl,
    title={TRL},
    author={HuggingFace},
    year={2024d},
    url={https://huggingface.co/docs/trl/en/index},
    note={TRL}
}

@misc{vidgen2024simplesafetyteststestsuiteidentifying,
      title={SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models}, 
      author={Bertie Vidgen and Nino Scherrer and Hannah Rose Kirk and Rebecca Qian and Anand Kannappan and Scott A. Hale and Paul Röttger},
      year={2024},
      eprint={2311.08370},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.08370}, 
}


@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@inproceedings{hartvigsen-etal-2022-toxigen,
    title = "{T}oxi{G}en: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection",
    author = "Hartvigsen, Thomas  and
      Gabriel, Saadia  and
      Palangi, Hamid  and
      Sap, Maarten  and
      Ray, Dipankar  and
      Kamar, Ece",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.234",
    doi = "10.18653/v1/2022.acl-long.234",
    pages = "3309--3326",
}






@article{Huang_2024,
   title={A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions},
   ISSN={1558-2868},
   url={http://dx.doi.org/10.1145/3703155},
   DOI={10.1145/3703155},
   journal={ACM Transactions on Information Systems},
   publisher={Association for Computing Machinery (ACM)},
   author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
   year={2024},
   month=nov }

@misc{bowen2024datapoisoningllmsjailbreaktuning,
      title={Data Poisoning in LLMs: Jailbreak-Tuning and Scaling Laws}, 
      author={Dillon Bowen and Brendan Murphy and Will Cai and David Khachaturov and Adam Gleave and Kellin Pelrine},
      year={2024},
      eprint={2408.02946},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2408.02946}, 
}

@misc{gallegos2024biasfairnesslargelanguage,
      title={Bias and Fairness in Large Language Models: A Survey}, 
      author={Isabel O. Gallegos and Ryan A. Rossi and Joe Barrow and Md Mehrab Tanjim and Sungchul Kim and Franck Dernoncourt and Tong Yu and Ruiyi Zhang and Nesreen K. Ahmed},
      year={2024},
      eprint={2309.00770},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.00770}, 
}

@misc{zhang2024ghostpastidentifyingresolving,
      title={"Ghost of the past": identifying and resolving privacy leakage from LLM's memory through proactive user interaction}, 
      author={Shuning Zhang and Lyumanshan Ye and Xin Yi and Jingyu Tang and Bo Shui and Haobin Xing and Pengfei Liu and Hewu Li},
      year={2024},
      eprint={2410.14931},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2410.14931}, 
}

@misc{benjamin2024systematicallyanalyzingpromptinjection,
      title={Systematically Analyzing Prompt Injection Vulnerabilities in Diverse LLM Architectures}, 
      author={Victoria Benjamin and Emily Braca and Israel Carter and Hafsa Kanchwala and Nava Khojasteh and Charly Landow and Yi Luo and Caroline Ma and Anna Magarelli and Rachel Mirin and Avery Moyer and Kayla Simpson and Amelia Skawinski and Thomas Heverin},
      year={2024},
      eprint={2410.23308},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2410.23308}, 
}

@misc{padhi2024graniteguardian,
      title={Granite Guardian}, 
      author={Inkit Padhi and Manish Nagireddy and Giandomenico Cornacchia and Subhajit Chaudhury and Tejaswini Pedapati and Pierre Dognin and Keerthiram Murugesan and Erik Miehling and Martín Santillán Cooper and Kieran Fraser and Giulio Zizzo and Muhammad Zaid Hameed and Mark Purcell and Michael Desmond and Qian Pan and Zahra Ashktorab and Inge Vejsbjerg and Elizabeth M. Daly and Michael Hind and Werner Geyer and Ambrish Rawat and Kush R. Varshney and Prasanna Sattigeri},
      year={2024},
      eprint={2412.07724},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.07724}, 
}

@misc{inan2023llamaguardllmbasedinputoutput,
      title={Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations}, 
      author={Hakan Inan and Kartikeya Upasani and Jianfeng Chi and Rashi Rungta and Krithika Iyer and Yuning Mao and Michael Tontchev and Qing Hu and Brian Fuller and Davide Testuggine and Madian Khabsa},
      year={2023},
      eprint={2312.06674},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.06674}, 
}

@misc{harmbenchexplore2024,
    title={HarmBench Explorer},
    author={{HarmBench}},
    year={2024},
    url={https://www.harmbench.org/explore}
}

@misc{shen2022rethinkevaluationattackstrength,
      title={Rethink the Evaluation for Attack Strength of Backdoor Attacks in Natural Language Processing}, 
      author={Lingfeng Shen and Haiyun Jiang and Lemao Liu and Shuming Shi},
      year={2022},
      eprint={2201.02993},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.02993}, 
}

@misc{wang2024decodingtrustcomprehensiveassessmenttrustworthiness,
      title={DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models}, 
      author={Boxin Wang and Weixin Chen and Hengzhi Pei and Chulin Xie and Mintong Kang and Chenhui Zhang and Chejian Xu and Zidi Xiong and Ritik Dutta and Rylan Schaeffer and Sang T. Truong and Simran Arora and Mantas Mazeika and Dan Hendrycks and Zinan Lin and Yu Cheng and Sanmi Koyejo and Dawn Song and Bo Li},
      year={2024},
      eprint={2306.11698},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.11698}, 
}

@misc{pan2023rewardsjustifymeansmeasuring,
      title={Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark}, 
      author={Alexander Pan and Jun Shern Chan and Andy Zou and Nathaniel Li and Steven Basart and Thomas Woodside and Jonathan Ng and Hanlin Zhang and Scott Emmons and Dan Hendrycks},
      year={2023},
      eprint={2304.03279},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2304.03279}, 
}

@article{bengio2024managingextremeaiaidrapidprogress,
author = {Yoshua Bengio  and Geoffrey Hinton  and Andrew Yao  and Dawn Song  and Pieter Abbeel  and Trevor Darrell  and Yuval Noah Harari  and Ya-Qin Zhang  and Lan Xue  and Shai Shalev-Shwartz  and Gillian Hadfield  and Jeff Clune  and Tegan Maharaj  and Frank Hutter  and Atılım Güneş Baydin  and Sheila McIlraith  and Qiqi Gao  and Ashwin Acharya  and David Krueger  and Anca Dragan  and Philip Torr  and Stuart Russell  and Daniel Kahneman  and Jan Brauner  and Sören Mindermann },
title = {Managing extreme AI risks amid rapid progress},
journal = {Science},
volume = {384},
number = {6698},
pages = {842-845},
year = {2024},
doi = {10.1126/science.adn0117},
URL = {https://www.science.org/doi/abs/10.1126/science.adn0117},
eprint = {https://www.science.org/doi/pdf/10.1126/science.adn0117},}


@misc{zhou2024stealtheditshf,
      title={Stealth Edits: Detecting Stealth Edits in LLM Outputs}, 
      author={Qinghua Zhou},
      year={2024},
      howpublished={HuggingFace Spaces},
      url={https://huggingface.co/spaces/qinghua-zhou/stealth-edits},
}

@article{siam2024exploitllms,
      title={How to Exploit Large Language Models for Good or Bad}, 
      author={Alec Edgington},
      year={2024},
      journal={SIAM News},
      volume={57},
      number={1},
      url={https://www.siam.org/publications/siam-news/articles/how-to-exploit-large-language-models-for-good-or-bad/},
}


@misc{sutton2024stealtheditslargelanguage,
      title={Stealth edits to large language models}, 
      author={Oliver J. Sutton and Qinghua Zhou and Wei Wang and Desmond J. Higham and Alexander N. Gorban and Alexander Bastounis and Ivan Y. Tyukin},
      year={2024},
      eprint={2406.12670},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2406.12670}, 
}

@misc{exabeam2024airegulations,
      title={AI Regulations and LLM Regulations: Past, Present, and Future}, 
      author={Exabeam},
      year={2024},
      howpublished={Exabeam Blog},
      url={https://www.exabeam.com/explainers/ai-cyber-security/ai-regulations-and-llm-regulations-past-present-and-future/},
}


@techreport{ema2024llmguidelines,
      title={Guiding principles for the use of large language models in regulatory science and medicines regulatory activities}, 
      author={{European Medicines Agency}},
      year={2024},
      institution={European Medicines Agency},
      type={Guidance Document},
      url={https://www.ema.europa.eu/en/documents/other/guiding-principles-use-large-language-models-regulatory-science-medicines-regulatory-activities_en.pdf},
}




@misc{alaga2024gradingrubricaisafety,
      title={A Grading Rubric for AI Safety Frameworks}, 
      author={Jide Alaga and Jonas Schuett and Markus Anderljung},
      year={2024},
      eprint={2409.08751},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2409.08751}, 
}

@techreport{unicef2024aiguidance,
      title={Policy Guidance on AI for Children}, 
      author={{UNICEF}},
      year={2024},
      institution={UNICEF Office of Research - Innocenti},
      type={Policy Report},
      url={https://www.unicef.org/innocenti/reports/policy-guidance-ai-children},
}










@article{doi:10.1098/rsos.240197,
author = {Wachter, Sandra  and Mittelstadt, Brent  and Russell, Chris },
title = {Do large language models have a legal duty to tell the truth?},
journal = {Royal Society Open Science},
volume = {11},
number = {8},
pages = {240197},
year = {2024},
doi = {10.1098/rsos.240197},

URL = {https://royalsocietypublishing.org/doi/abs/10.1098/rsos.240197},
eprint = {https://royalsocietypublishing.org/doi/pdf/10.1098/rsos.240197}
}

@misc{china2023generativeai,
      title={China: Generative AI Measures Finalized},
      author={{Library of Congress}},
      year={2023},
      institution={Law Library of Congress},
      type={Global Legal Monitor},
      month={July},
      url={https://www.loc.gov/item/global-legal-monitor/2023-07-18/china-generative-ai-measures-finalized/},
}

@techreport{nist2024riskframework,
      title={AI Risk Management Framework}, 
      author={{National Institute of Standards and Technology}},
      year={2024},
      institution={National Institute of Standards and Technology},
      type={Technical Report},
      url={https://www.nist.gov/itl/ai-risk-management-framework},
}


@techreport{openai2024preparedness,
      title={OpenAI Preparedness Framework}, 
      author={{OpenAI}},
      year={2024},
      institution={OpenAI},
      type={Technical Report},
      url={https://cdn.openai.com/openai-preparedness-framework-beta.pdf},
}

@techreport{anthropic2024scaling,
      title={Anthropic's Responsible Scaling Policy}, 
      author={{Anthropic}},
      year={2024},
      institution={Anthropic},
      type={Technical Report},
      url={https://www-cdn.anthropic.com/1adf000c8f675958c2ee23805d91aaade1cd4613/responsible-scaling-policy.pdf},
}

@techreport{deepmind2024frontier,
      title={The Frontier Safety Framework}, 
      author={{DeepMind}},
      year={2024},
      institution={DeepMind},
      type={Technical Report},
      url={https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/introducing-the-frontier-safety-framework/fsf-technical-report.pdf},
}

@misc{perez2022redteaminglanguagemodels,
      title={Red Teaming Language Models with Language Models}, 
      author={Ethan Perez and Saffron Huang and Francis Song and Trevor Cai and Roman Ring and John Aslanides and Amelia Glaese and Nat McAleese and Geoffrey Irving},
      year={2022},
      eprint={2202.03286},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2202.03286}, 
}

@misc{cambria2024xaimeetsllmssurvey,
      title={XAI meets LLMs: A Survey of the Relation between Explainable AI and Large Language Models}, 
      author={Erik Cambria and Lorenzo Malandri and Fabio Mercorio and Navid Nobani and Andrea Seveso},
      year={2024},
      eprint={2407.15248},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.15248}, 
}

@misc{askell2023constitutionalai,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Amanda Askell and Yuntao Bai and Anna Chen and Deep Ganguli and Danny Hernandez and Jared Kaplan and Jackson Kernion and Ben Mann and Catherine Olsson and Paul Christiano},
      year={2023},
      institution={Anthropic},
      url={https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback},
}

@misc{li2024saladbenchhierarchicalcomprehensivesafety,
      title={SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models}, 
      author={Lijun Li and Bowen Dong and Ruohui Wang and Xuhao Hu and Wangmeng Zuo and Dahua Lin and Yu Qiao and Jing Shao},
      year={2024},
      eprint={2402.05044},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.05044}, 
}

@misc{opensafetylab2024saladdata,
      title={Salad-Data: A Hierarchical and Comprehensive Safety Dataset for Large Language Models},
      author={{OpenSafetyLab}},
      year={2024},
      howpublished={HuggingFace Dataset},
      url={https://huggingface.co/datasets/OpenSafetyLab/Salad-Data},
}

@misc{opensafetylab2024saladbenchleaderboard,
      title={Salad-Bench Leaderboard},
      author={{OpenSafetyLab}},
      year={2024},
      howpublished={HuggingFace Space},
      url={https://huggingface.co/spaces/OpenSafetyLab/Salad-Bench-Leaderboard},
}

@misc{gptfuzzer2024,
      title={GPTFuzzer: Red Teaming Large Language Models with Auto-Generated Safety Test Cases}, 
      author={Jiahao Yu and Xingwei Lin and Xinyu Xing},
      year={2024},
      howpublished={Papers with Code},
      url={https://paperswithcode.com/dataset/gptfuzzer},
}

@book{derman2011models,
  title={Models.Behaving.Badly.: Why Confusing Illusion with Reality Can Lead to Disaster, on Wall Street and in Life},
  author={Derman, E.},
  isbn={9781439165010},
  lccn={2011015006},
  url={https://books.google.co.uk/books?id=lke_cwM4wm8C},
  year={2011},
  publisher={Free Press}
}


@misc{safebench2024,
      title={SafeBench: A Comprehensive Benchmark for LLM Safety Evaluation},
      author={{ML Safety Team}},
      year={2024},
      howpublished={ML Safety Website},
      url={https://www.mlsafety.org/safebench},
}


@misc{mazeika2024harmbenchstandardizedevaluationframework,
      title={HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal}, 
      author={Mantas Mazeika and Long Phan and Xuwang Yin and Andy Zou and Zifan Wang and Norman Mu and Elham Sakhaee and Nathaniel Li and Steven Basart and Bo Li and David Forsyth and Dan Hendrycks},
      year={2024},
      eprint={2402.04249},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2402.04249}, 
}

@misc{harmbench2024,
    title={HarmBench},
    author={{Center for AI Safety}},
    year={2024},
    howpublished={GitHub repository},
    url={https://github.com/centerforaisafety/HarmBench},
    note={Framework for evaluating language model safety}
}

@misc{harmbenchresults2024,
    title={HarmBench Leaderboard},
    author={{Center for AI Safety}},
    year={2024},
    url={https://www.harmbench.org/results},
    note={Leaderboard tracking performance of language models on safety benchmarks}
}


@misc{guha2023legalbench,
      title={LegalBench: A Collaboratively Built Benchmark for Measuring Legal Reasoning in Large Language Models}, 
      author={Neel Guha and Julian Nyarko and Daniel E. Ho and Christopher Ré and Adam Chilton and Aditya Narayana and Alex Chohlas-Wood and Austin Peters and Brandon Waldon and Daniel N. Rockmore and Diego Zambrano and Dmitry Talisman and Enam Hoque and Faiz Surani and Frank Fagan and Galit Sarfaty and Gregory M. Dickinson and Haggai Porat and Jason Hegland and Jessica Wu and Joe Nudell and Joel Niklaus and John Nay and Jonathan H. Choi and Kevin Tobia and Margaret Hagan and Megan Ma and Michael Livermore and Nikon Rasumov-Rahe and Nils Holzenberger and Noam Kolt and Peter Henderson and Sean Rehaag and Sharad Goel and Shang Gao and Spencer Williams and Sunny Gandhi and Tom Zur and Varun Iyer and Zehua Li},
      year={2023},
      eprint={2308.11462},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.11462}, 
}

@misc{surgeaiprofanity2024,
    title={Surge AI Profanity Dataset},
    author={{Surge AI}},
    year={2024},
    howpublished={GitHub repository},
    url={https://github.com/surge-ai/profanity},
    note={A comprehensive dataset for training and evaluating profanity detection models}
}


@misc{
zhang2024finbench,
title={FinBench: Benchmarking {LLM}s in Complex Financial Problem Solving and Reasoning},
author={Zhihan Zhang and Yixin Cao and Lizi Liao},
year={2024},
url={https://openreview.net/forum?id=AeGrf1uY0p}
}

@article{patil2023gorilla,
  title={Gorilla: Large Language Model Connected with Massive APIs},
  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
  year={2023},
  journal={arXiv preprint arXiv:2305.15334},
} 

@misc{mistralmoderation2024,
    title={Mistral Moderation: A Technical Report},
    author={{Mistral AI}},
    year={2024},
    url={https://mistral.ai/news/mistral-moderation/}
}

@misc{openaimoderation2024,
    title={OpenAI Moderation API},
    author={{OpenAI}},
    year={2024},
    url={https://platform.openai.com/docs/guides/moderation},
    note={Documentation for OpenAI's content moderation API}
}

@misc{llmguard2024,
    title={LLM-Guard: Comprehensive Safety and Security Framework for Large Language Models},
    author={{ProtectAI}},
    year={2024},
    url={https://github.com/protectai/llm-guard},
    note={An open-source toolkit for LLM security and safety}
}

@misc{nemogr2024,
    title={NeMo-Guardrails: An Open-Source Toolkit for Building Reliable and Safe LLM Applications},
    author={{NVIDIA}},
    year={2024},
    url={https://github.com/NVIDIA/NeMo-Guardrails},
    note={A framework for creating reliable and safe LLM applications with customizable guardrails}
}

@misc{awscomprehend2024,
    title={Amazon Comprehend - Natural Language Processing Service},
    author={{Amazon Web Services}},
    year={2024},
    url={https://aws.amazon.com/comprehend/},
    note={AWS natural language processing service for text analysis and content moderation}
}

@misc{hendrycks2022unsolvedproblemsmlsafety,
      title={Unsolved Problems in ML Safety}, 
      author={Dan Hendrycks and Nicholas Carlini and John Schulman and Jacob Steinhardt},
      year={2022},
      eprint={2109.13916},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2109.13916}, 
}

@misc{ibmriskatlas2024,
    title={IBM watsonx.ai Risk Atlas},
    author={{IBM}},
    year={2024},
    url={https://www.ibm.com/docs/en/watsonx/saas?topic=ai-risk-atlas},
    note={A framework for identifying and mitigating risks in AI systems}
}




@misc{mistral2024,
    title={System-Level Guardrails for Mistral},
    author={{Mistral}},
    year={2024},
    url={https://github.com/mistralai/cookbook/blob/main/mistral/moderation/system-level-guardrails.ipynb},
    note={A Jupyter notebook detailing system-level guardrails for Mistral models}
}


@article{ren2024reconciling,
  title={Reconciling the contrasting narratives on the environmental impact of large language models},
  author={Ren, Shaolei and others},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={26310},
  year={2024},
  publisher={Nature Publishing Group},
  doi={10.1038/s41598-024-76682-6}
}

@misc{epa2023greenhouse,
    title={Greenhouse Gas Emissions from a Typical Passenger Vehicle},
    author={{United States Environmental Protection Agency}},
    year={2023},
    howpublished={Website},
    url={https://www.epa.gov/greenvehicles/greenhouse-gas-emissions-typical-passenger-vehicle}
}

@misc{anthropic2024statistical,
    title={A Statistical Approach to Model Evaluation},
    author={{Anthropic}},
    year={2024},
    howpublished={Website},
    url={https://www.anthropic.com/research/statistical-approach-to-model-evals}
}

@misc{bcs2024deadend,
    title={Does current AI represent a dead end?},
    author={{British Computer Society}},
    year={2024},
    howpublished={Website},
    url={https://www.bcs.org/articles-opinion-and-research/does-current-ai-represent-a-dead-end/}
}



@article{oketunji2023a,
  edition = {},
  number = {},
  journal = {Data \& Policy},
  pages = {},
  publisher = {Cambridge University Press},
  school = {},
  title = {Large Language Model (LLM) Bias Index—LLMBI},
  volume = {},
  author = {Oketunji, AF and Anas, M and Saina, D},
  editor = {},
  year = {2023},
  series = {}
}

@misc{chen2023combatingmisinformationagellms,
      title={Combating Misinformation in the Age of LLMs: Opportunities and Challenges}, 
      author={Canyu Chen and Kai Shu},
      year={2023},
      eprint={2311.05656},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2311.05656}, 
}

@misc{crfm2021website,
    title={Introducing the Center for Research on Foundation Models (CRFM)},
    author={{Stanford HAI}},
    year={2021},
    howpublished={Website},
    url={https://hai.stanford.edu/news/introducing-center-research-foundation-models-crfm}
}

@misc{xu2024benchmarkdatacontaminationlarge,
      title={Benchmark Data Contamination of Large Language Models: A Survey}, 
      author={Cheng Xu and Shuhao Guan and Derek Greene and M-Tahar Kechadi},
      year={2024},
      eprint={2406.04244},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.04244}, 
}


@misc{ollama2024website,
    title={Ollama: Get up and running with large language models, locally},
    author={Ollama},
    year={2024},
    howpublished={Website},
    url={https://ollama.com}
}

@misc{langchain_github,
      title={LangChain},
      author={{LangChain}},
      year={2024z},
      howpublished={\url{https://github.com/langchain-ai/langchain}},
      note={Accessed: 12/07/2024}
}

@misc{bengio2014representationlearningreviewnew,
      title={Representation Learning: A Review and New Perspectives}, 
      author={Yoshua Bengio and Aaron Courville and Pascal Vincent},
      year={2014},
      eprint={1206.5538},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1206.5538}, 
}

@misc{liu2024enhancingllmscognitionstructurization,
      title={Enhancing LLM's Cognition via Structurization}, 
      author={Kai Liu and Zhihang Fu and Chao Chen and Wei Zhang and Rongxin Jiang and Fan Zhou and Yaowu Chen and Yue Wu and Jieping Ye},
      year={2024},
      eprint={2407.16434},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.16434}, 
}

@misc{jacob2024drowningdocumentsconsequencesscaling,
      title={Drowning in Documents: Consequences of Scaling Reranker Inference}, 
      author={Mathew Jacob and Erik Lindgren and Matei Zaharia and Michael Carbin and Omar Khattab and Andrew Drozdov},
      year={2024},
      eprint={2411.11767},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2411.11767}, 
}

@misc{li2024retrollmempoweringlargelanguage,
      title={RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation}, 
      author={Xiaoxi Li and Jiajie Jin and Yujia Zhou and Yongkang Wu and Zhonghua Li and Qi Ye and Zhicheng Dou},
      year={2024},
      eprint={2412.11919},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.11919}, 
}



@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}

@misc{lee2024longcontextlanguagemodelssubsume,
      title={Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?}, 
      author={Jinhyuk Lee and Anthony Chen and Zhuyun Dai and Dheeru Dua and Devendra Singh Sachan and Michael Boratko and Yi Luan and Sébastien M. R. Arnold and Vincent Perot and Siddharth Dalmia and Hexiang Hu and Xudong Lin and Panupong Pasupat and Aida Amini and Jeremy R. Cole and Sebastian Riedel and Iftekhar Naim and Ming-Wei Chang and Kelvin Guu},
      year={2024},
      eprint={2406.13121},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.13121}, 
}

@misc{li2024retrievalaugmentedgenerationlongcontext,
      title={Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach}, 
      author={Zhuowan Li and Cheng Li and Mingyang Zhang and Qiaozhu Mei and Michael Bendersky},
      year={2024},
      eprint={2407.16833},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.16833}, 
}

@misc{ragas2024evaluation,
    title={RAG Evaluation - Ragas Documentation},
    author={{Ragas}},
    year={2024},
    howpublished={Website},
    url={https://docs.ragas.io/en/stable/getstarted/rag_evaluation/}
}


@misc{wu2024longdocumentsummaryevaluation,
      title={Less is More for Long Document Summary Evaluation by LLMs}, 
      author={Yunshu Wu and Hayate Iso and Pouya Pezeshkpour and Nikita Bhutani and Estevam Hruschka},
      year={2024},
      eprint={2309.07382},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.07382}, 
}

@misc{he2024doespromptformattingimpact,
      title={Does Prompt Formatting Have Any Impact on LLM Performance?}, 
      author={Jia He and Mukund Rungta and David Koleczek and Arshdeep Sekhon and Franklin X Wang and Sadid Hasan},
      year={2024},
      eprint={2411.10541},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.10541}, 
}

@misc{huggingface2024mteb,
    title={Massive Text Embedding Benchmark (MTEB) Leaderboard},
    author={{HuggingFace}},
    year={2024i},
    howpublished={Website},
    url={https://huggingface.co/spaces/mteb/leaderboard}
}


@misc{llamaindex2024storing,
    title={Storing - LlamaIndex Documentation},
    author={{LlamaIndex}},
    year={2024},
    howpublished={Website},
    url={https://docs.llamaindex.ai/en/stable/understanding/storing/storing/}
}


@misc{zenml2024rag,
    title={Scaling RAG Accuracy from 49\% to 86\% in Finance Q\&A Assistant},
    author={{ZenML}},
    year={2024},
    howpublished={Website},
    url={https://www.zenml.io/llmops-database/scaling-rag-accuracy-from-49-to-86-in-finance-q-a-assistant}
}


@misc{sentencetransformers2024website,
    title={Sentence Transformers},
    author={{HuggingFace}},
    year={2024f},
    howpublished={Website},
    url={https://huggingface.co/sentence-transformers}
}


@misc{chromadb2024docs,
    title={ChromaDB Documentation},
    author={{ChromaDB}},
    year={2024b},
    howpublished={Website},
    url={https://docs.trychroma.com/}
}


@misc{openai2024embeddings,
    title={What are embeddings?},
    author={{OpenAI}},
    year={2024},
    howpublished={Website},
    url={https://platform.openai.com/docs/guides/embeddings/what-are-embeddings}
}

@misc{chromadb2024hnsw,
    title={ChromaDB Cookbook: HNSW Configuration},
    author={{ChromaDB}},
    year={2024a},
    howpublished={Website},
    url={https://cookbook.chromadb.dev/core/configuration/#hnsw-configuration}
}

@misc{gibsondunn2024regulating,
    title={Regulating the Future: Eight Key Takeaways from California's SB 1047, Vetoed by Governor Newsom},
    author={{Gibson Dunn}},
    year={2024},
    howpublished={Website},
    url={https://www.gibsondunn.com/regulating-the-future-eight-key-takeaways-from-californias-sb-1047-vetoed-by-governor-newsom/}
}
@misc{argilla2024distilabel,
    title={Distilabel Documentation},
    author={{Argilla}},
    year={2024},
    howpublished={Website},
    url={https://distilabel.argilla.io/latest/},
    note={Distilabel}
}
@misc{lambert2025posttraining,
    title={NeurIPS 2024 Tutorial:The State of Post-Training},
    author={Nathan Lambert},
    year={2025},
    month={January},
    howpublished={Presentation},
    url={https://docs.google.com/presentation/d/1FL6pzRT3tjCfJ985emS_2YfujCe_iz6dsyRcDIUFPqs/}
}
@misc{huggingface2024smolcourse,
    title={Smol Course},
    author={HuggingFace},
    year={2024i},
    howpublished={GitHub repository},
    url={https://github.com/huggingface/smol-course}
}



@misc{wen2024languagemodelslearnmislead,
      title={Language Models Learn to Mislead Humans via RLHF}, 
      author={Jiaxin Wen and Ruiqi Zhong and Akbir Khan and Ethan Perez and Jacob Steinhardt and Minlie Huang and Samuel R. Bowman and He He and Shi Feng},
      year={2024},
      eprint={2409.12822},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2409.12822}, 
}

