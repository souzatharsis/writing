<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-f8dc6eab18fde03278982b0b35885446.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Thársis Souza, Ph.D.">
  <meta name="dcterms.date" content="2025-01-28">
  <title>tllms-code – Taming LLMs</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #e1e4e8; background-color: #24292e; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #e1e4e8; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #f97583; } /* Attribute */
    code span.bn { color: #79b8ff; } /* BaseN */
    code span.bu { color: #f97583; } /* BuiltIn */
    code span.cf { color: #f97583; } /* ControlFlow */
    code span.ch { color: #9ecbff; } /* Char */
    code span.cn { color: #79b8ff; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #f97583; } /* DataType */
    code span.dv { color: #79b8ff; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #f97583; font-weight: bold; } /* Extension */
    code span.fl { color: #79b8ff; } /* Float */
    code span.fu { color: #b392f0; } /* Function */
    code span.im { color: #9ecbff; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #f97583; } /* Keyword */
    code span.op { color: #e1e4e8; } /* Operator */
    code span.ot { color: #b392f0; } /* Other */
    code span.pp { color: #f97583; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #79b8ff; } /* SpecialChar */
    code span.ss { color: #9ecbff; } /* SpecialString */
    code span.st { color: #9ecbff; } /* String */
    code span.va { color: #ffab70; } /* Variable */
    code span.vs { color: #9ecbff; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-5b48f34d633aed70c74c672477009ffc.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Taming LLMs</h1>
  <p class="subtitle">A Practical Guide to LLM Pitfalls with Open Source Software</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Thársis Souza, Ph.D. 
</div>
</div>
</div>

  <p class="date">2025-01-28</p>
</section>
<section id="about-me" class="slide level2" data-auto-animate="true" data-auto-animate-easing="ease-in-out">
<h2 data-id="quarto-animate-title">About Me</h2>
<div class="r-stack">
<div data-id="box1" style="background: #e83e8c; width: 350px; height: 350px; border-radius: 200px;">
<p>CS</p>
</div>
<div data-id="box2" style="background: #3fb618; width: 250px; height: 250px; border-radius: 200px;">
<p>PM</p>
</div>
<div data-id="box3" style="background: #2780e3; width: 150px; height: 150px; border-radius: 200px;">
<p>Finance</p>
</div>
</div>
</section>
<section id="about-me-1" class="slide level2" data-auto-animate="true" data-auto-animate-easing="ease-in-out">
<h2 data-id="quarto-animate-title">About Me</h2>
<div class="r-hstack">
<div style="display: flex; flex-direction: column; align-items: center;">
<div data-id="box1" data-auto-animate-delay="0" style="background: #e83e8c; width: 200px; height: 150px; margin: 10px; display: flex; justify-content: center; align-items: center;">
<p><strong>CS</strong></p>
</div>
<div style="width: 2px; height: 30px; background: #e83e8c;">

</div>
<p>PhD, UCL</p>
</div>
<div style="display: flex; flex-direction: column; align-items: center;">
<div data-id="box2" data-auto-animate-delay="0.1" style="background: #3fb618; width: 200px; height: 150px; margin: 10px; display: flex; justify-content: center; align-items: center;">
<p><strong>PM</strong></p>
</div>
<div style="width: 2px; height: 30px; background: #3fb618;">

</div>
<p>SF</p>
</div>
<div style="display: flex; flex-direction: column; align-items: center;">
<div data-id="box3" data-auto-animate-delay="0.2" style="background: #2780e3; width: 200px; height: 150px; margin: 10px; display: flex; justify-content: center; align-items: center;">
<p><strong>Finance</strong></p>
</div>
<div style="width: 2px; height: 30px; background: #2780e3;">

</div>
<p>Ex-Two Sigma</p>
</div>
</div>
</section>
<section id="agenda" class="slide level2">
<h2>Agenda</h2>
<ol type="1">
<li>LLM Pitfalls</li>
<li>Case Study: Safety &amp; Alignment</li>
<li>Discussion</li>
</ol>
</section>
<section id="llm-pitfalls" class="slide level2">
<h2>LLM Pitfalls</h2>

<img data-src="images/bad.jpeg" class="r-stretch quarto-figure-center" id="fig-bad"><p class="caption">
Figure&nbsp;1: <em>Samuel Colvin, Pydantic</em>
</p></section>
<section id="llm-pitfalls-1" class="slide level2">
<h2>LLM Pitfalls</h2>
<blockquote>
<p>From the perspective of software engineering, current AI systems are unmanageable, and as a consequence their use in serious contexts is irresponsible.</p>
</blockquote>
<p>– Prof.&nbsp;Eerke Boiten, Head of School of Computer Science and Informatics at De Montfort University (DMU), Leicester, UK. <a href="https://www.bcs.org/articles-opinion-and-research/does-current-ai-represent-a-dead-end/">source</a></p>
</section>
<section id="llm-pitfalls-2" class="slide level2">
<h2>LLM Pitfalls</h2>
<div class="r-stack">
<div class="r-hstack" style="flex-wrap: wrap; justify-content: center; align-items: center; max-width: 1200px;">
<div class="fragment" style="background: #e83e8c; width: 300px; height: 150px; margin: 10px; padding: 15px; border-radius: 15px; display: flex; justify-content: center; align-items: center;">
<h3 id="testing-complexity">Testing Complexity</h3>
</div>
<div class="fragment" style="background: #ff7518; width: 300px; height: 150px; margin: 10px; padding: 15px; border-radius: 15px; display: flex; justify-content: center; align-items: center;">
<h3 id="structural-unreliability">Structural (un)Reliability</h3>
</div>
<div class="fragment" style="background: #3fb618; width: 300px; height: 150px; margin: 10px; padding: 15px; border-radius: 15px; display: flex; justify-content: center; align-items: center;">
<h3 id="input-data-issues">Input Data Issues</h3>
</div>
<div class="fragment" style="background: #2780e3; width: 300px; height: 150px; margin: 10px; padding: 15px; border-radius: 15px; display: flex; justify-content: center; align-items: center;">
<h3 id="safety">Safety</h3>
</div>
<div class="fragment" style="background: #9954bb; width: 300px; height: 150px; margin: 10px; padding: 15px; border-radius: 15px; display: flex; justify-content: center; align-items: center;">
<h3 id="alignment">Alignment</h3>
</div>
<div class="fragment" style="background: #20c997; width: 300px; height: 150px; margin: 10px; padding: 15px; border-radius: 15px; display: flex; justify-content: center; align-items: center;">
<h3 id="vendor-lock-in">Vendor <br> Lock-in</h3>
</div>
<div class="fragment" style="background: #6f42c1; width: 1000px; height: 150px; margin: 10px; padding: 15px; border-radius: 15px; display: flex; justify-content: center; align-items: center;">
<h3 id="cost-performance-optimization">Cost &amp; Performance Optimization</h3>
</div>
</div>
</div>
</section>
<section id="section" class="slide level2">
<h2></h2>
<section id="testing-complexity-1" style="background: #e83e8c; width: 100%; height: 100vh; margin: 0; padding: 15px; display: flex; justify-content: center; align-items: center; text-align: center; align-content: center;">
<h3>Testing Complexity</h3>
</section>
</section>
<section id="testing-complexity-2" class="slide level2">
<h2>Testing Complexity</h2>
<p>LLMs are Generative, Non-Deterministic, and have Emergent Properties.</p>

<img data-src="images/emergent-properties-palm.gif" style="width:100.0%" class="r-stretch quarto-figure-center"><p class="caption">LLMs “Emerging Properties” Phenomenon. From: “Pathways Language Model (PaLM): Scaling to 540 Billion Parameters for Breakthrough Performance”</p></section>
<section id="testing-complexity-3" class="slide level2 smaller">
<h2>Testing Complexity</h2>
<table class="caption-top">
<colgroup>
<col style="width: 19%">
<col style="width: 41%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Aspect</th>
<th>Traditional Software Products</th>
<th>LLM-Based Software Products</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Capability Assessment</td>
<td>Validates specific functionality against requirements</td>
<td>May assess emergent properties like reasoning and creativity</td>
</tr>
<tr class="even">
<td style="text-align: left;">Metrics and Measurement</td>
<td>Precisely defined and measurable metrics</td>
<td>Subjective qualities that resist straightforward quantification</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Dataset Contamination</td>
<td>Uses carefully crafted test cases</td>
<td>Risk of memorized evaluation examples from training</td>
</tr>
<tr class="even">
<td style="text-align: left;">Benchmark Evolution</td>
<td>Maintains stable test suites</td>
<td>Continuously evolving benchmarks as capabilities advance</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Human Evaluation</td>
<td>Mostly automated validation</td>
<td>May require significant human oversight</td>
</tr>
</tbody>
</table>
</section>
<section id="testing-complexity-evals-design" class="slide level2">
<h2>Testing Complexity: Evals Design</h2>

<img data-src="images/conceptual-multi.svg" class="r-stretch quarto-figure-center" id="fig-conceptual-multi"><p class="caption">
Figure&nbsp;2: Conceptual overview of Multiple LLM-based applications evaluation.
</p></section>
<section id="testing-complexity-tools" class="slide level2 smaller">
<h2>Testing Complexity: Tools</h2>
<div class="panel-tabset">
<ul id="tabset-1" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-1-1">LightEval</a></li><li><a href="#tabset-1-2">LangSmith</a></li><li><a href="#tabset-1-3">PromptFoo</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1">
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a></a><span class="ex">lighteval</span> accelerate <span class="at">--model_args</span> <span class="st">"pretrained=meta-llama/Llama-3.2-1B-Instruct"</span> <span class="at">--tasks</span> <span class="st">"leaderboard|mmlu:econometrics|0|0"</span> <span class="at">--output_dir</span><span class="op">=</span><span class="st">"./evals/"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-2">
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="kw">def</span> run_evaluation(app, model_name, dataset,  evaluators):</span>
<span id="cb2-2"><a></a>    results <span class="op">=</span> langsmith_evaluate(</span>
<span id="cb2-3"><a></a>        app,</span>
<span id="cb2-4"><a></a>        data<span class="op">=</span>dataset,</span>
<span id="cb2-5"><a></a>        evaluators<span class="op">=</span>evaluators,</span>
<span id="cb2-6"><a></a>        experiment_prefix<span class="op">=</span>model_name,</span>
<span id="cb2-7"><a></a>        num_repetitions<span class="op">=</span><span class="dv">5</span></span>
<span id="cb2-8"><a></a>    )</span>
<span id="cb2-9"><a></a>    <span class="cf">return</span> results</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-3">
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource yaml number-lines code-with-copy"><code class="sourceCode yaml"><span id="cb3-1"><a></a><span class="fu">description</span><span class="kw">:</span><span class="at"> Best model eval</span></span>
<span id="cb3-2"><a></a><span class="fu">prompts</span><span class="kw">:</span></span>
<span id="cb3-3"><a></a><span class="kw">-</span><span class="at"> file://prompt1.txt</span></span>
<span id="cb3-4"><a></a><span class="kw">-</span><span class="at"> file://prompt2.txt</span></span>
<span id="cb3-5"><a></a><span class="kw">-</span><span class="at"> file://prompt3.txt</span></span>
<span id="cb3-6"><a></a><span class="fu">providers</span><span class="kw">:</span></span>
<span id="cb3-7"><a></a><span class="kw">-</span><span class="at"> openai:gpt-3.5-turbo</span></span>
<span id="cb3-8"><a></a><span class="fu">defaultTest</span><span class="kw">:</span></span>
<span id="cb3-9"><a></a><span class="at">  </span><span class="fu">assert</span><span class="kw">:</span></span>
<span id="cb3-10"><a></a><span class="at">  </span><span class="kw">-</span><span class="at"> </span><span class="fu">type</span><span class="kw">:</span><span class="at"> llm-rubric</span></span>
<span id="cb3-11"><a></a><span class="at">    </span><span class="fu">value</span><span class="kw">:</span><span class="at"> </span><span class="st">'Evaluate the output based on how detailed it is.  Grade it on a scale</span></span>
<span id="cb3-12"><a></a><span class="st">      of 0.0 to 1.0, where:</span></span>
<span id="cb3-13"><a></a></span>
<span id="cb3-14"><a></a><span class="st">      Score of 0.1: Not much detail.</span></span>
<span id="cb3-15"><a></a></span>
<span id="cb3-16"><a></a><span class="st">      Score of 0.5: Some detail.</span></span>
<span id="cb3-17"><a></a></span>
<span id="cb3-18"><a></a><span class="st">      Score of 1.0: Very detailed.</span></span>
<span id="cb3-19"><a></a></span>
<span id="cb3-20"><a></a><span class="st">      '</span></span>
<span id="cb3-21"><a></a><span class="fu">tests</span><span class="kw">:</span><span class="at"> file://tests.csv</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="testing-complexity-tools-1" class="slide level2 smaller">
<h2>Testing Complexity: Tools</h2>

<img data-src="images/evals_compare.png" style="width:100.0%" class="r-stretch"></section>
<section id="testing-complexity-4" class="slide level2 smaller">
<h2>Testing Complexity</h2>
<p><strong>Takeaways</strong></p>
<div>
<ul>
<li class="fragment">Testing LLMs requires a fundamental mindset shift from deterministic to probabilistic evaluation
<ul>
<li class="fragment">Traditional software testing methods are inadequate for LLM variability</li>
<li class="fragment">Success requires embracing comprehensive evaluation frameworks</li>
<li class="fragment">Evaluation is the new Product Requirements Document (PRD)</li>
</ul></li>
</ul>
</div>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<section id="structural-unreliability-1" style="background: #ff7518; width: 100%; height: 100vh; margin: 0; padding: 15px; display: flex; justify-content: center; align-items: center; text-align: center; align-content: center;">
<h3>Structural (un)Reliability</h3>
</section>
</section>
<section id="structural-unreliability-2" class="slide level2">
<h2>Structural (un)Reliability</h2>
<div>
<ul>
<li class="fragment">Language Models excel at generating human-like text but struggle with producing structured output consistently <span class="citation" data-cites="tang2024strucbenchlargelanguagemodels shorten2024structuredragjsonresponseformatting">(<a href="#/references" role="doc-biblioref" onclick="">Tang et al. 2024</a>; <a href="#/references" role="doc-biblioref" onclick="">Shorten et al. 2024</a>)</span></li>
<li class="fragment">This limitation poses significant challenges when integrating LLMs into production systems
<ul>
<li class="fragment">Databases</li>
<li class="fragment">APIs</li>
<li class="fragment">Other software applications</li>
</ul></li>
<li class="fragment">Even carefully crafted prompts cannot guarantee consistent structural adherence in LLM responses</li>
</ul>
</div>
</section>
<section id="structural-unreliability-3" class="slide level2 smaller">
<h2>Structural (un)Reliability</h2>
<p>But what user needs drive the demand for LLM output constraints? A recent Google Research <span class="citation" data-cites="10.1145/3613905.3650756">(<a href="#/references" role="doc-biblioref" onclick="">M. X. Liu et al. 2024</a>)</span> study explored this question through a survey of 51 industry professionals who use LLMs in their work:</p>
<div>
<ul>
<li class="fragment"><strong>Improving Developer Efficiency and Workflow</strong>
<ul>
<li class="fragment">Reducing trial and error in prompt engineering</li>
<li class="fragment">Minimizing post-processing of LLM outputs</li>
<li class="fragment">Streamlining integration with downstream processes</li>
<li class="fragment">Enhancing quality of synthetic datasets</li>
</ul></li>
<li class="fragment"><strong>Meeting UI and Product Requirements</strong>
<ul>
<li class="fragment">Adhering to UI size limitations</li>
<li class="fragment">Ensuring output consistency</li>
</ul></li>
<li class="fragment"><strong>Enhancing User Trust and Experience</strong>
<ul>
<li class="fragment">Mitigating hallucinations</li>
<li class="fragment">Driving user adoption</li>
</ul></li>
</ul>
</div>
<!-- To constrain LLM output is not just a technical consideration but a fundamental user need, impacting developer efficiency and user experience. -->
</section>
<section id="structural-unreliability-4" class="slide level2 smaller">
<h2>Structural (un)Reliability</h2>
<p>The text generation process follows a probabilistic approach. At each step, the model calculates the probability distribution over its entire vocabulary to determine the most likely next token:</p>
<p><span class="math display">\[\begin{equation}
P(X) = P(x_1, x_2, \ldots, x_n) = \prod_{i=1}^n p(x_i|x_{&lt;i})
\end{equation}\]</span></p>
<p>where, <span class="math inline">\(x_i\)</span> represents the current token being generated, while <span class="math inline">\(x_{&lt;i}\)</span> encompasses all preceding tokens.</p>

<img data-src="images/logit.svg" class="r-stretch quarto-figure-center" id="fig-logit"><p class="caption">
Figure&nbsp;3: Text Generation Process: “Sampling”.
</p></section>
<section id="structural-unreliability-5" class="slide level2 smaller">
<h2>Structural (un)Reliability</h2>
<p>This controlled text generation process can be formalized as <span class="citation" data-cites="liang2024controllabletextgenerationlarge">(<a href="#/references" role="doc-biblioref" onclick="">Liang et al. 2024</a>)</span>:</p>
<p><span class="math display">\[\begin{equation}
P(X|\color{green}{C}) = P(x_1, x_2, \ldots, x_n|\color{green}{C}) = \prod_{i=1}^n p(x_i|x_{&lt;i}, \color{green}{C})
\end{equation}\]</span></p>
<p>Here, <span class="math inline">\(\color{green}{C}\)</span> represents the set of constraints or control conditions that shape the generated output.</p>
</section>
<section id="structural-unreliability-6" class="slide level2 smaller">
<h2>Structural (un)Reliability</h2>
<p>Common constraints (<span class="math inline">\(C\)</span>) include:</p>
<div>
<ul>
<li class="fragment"><p><strong>Format Constraints</strong>: Enforcing specific output formats like JSON, XML, or YAML ensures the generated content follows a well-defined structure that can be easily parsed and validated. Format constraints are essential for system integration and data exchange.</p></li>
<li class="fragment"><p><strong>Multiple Choice Constraints</strong>: Restricting LLM outputs to a predefined set of options helps ensure valid responses and reduces the likelihood of unexpected or invalid outputs. This is particularly useful for classification tasks or when specific categorical responses are required.</p></li>
<li class="fragment"><p><strong>Static Typing Constraints</strong>: Enforcing data type requirements (strings, integers, booleans, etc.) ensures outputs can be safely processed by downstream systems. Type constraints help prevent runtime errors and improve system reliability.</p></li>
<li class="fragment"><p><strong>Length Constraints</strong>: Limiting the length of generated content is crucial for UI display, platform requirements (like Twitter’s character limit), and maintaining consistent user experience. Length constraints can be applied at the character, word, or token level.</p></li>
<li class="fragment"><p><strong>Ensuring Output Consistency</strong>: Consistent output length and format are crucial for user experience and UI clarity. Constraints help maintain this consistency, avoiding overwhelming variability in generated text.</p></li>
</ul>
</div>
</section>
<section id="structural-unreliability-7" class="slide level2 smaller">
<h2>Structural (un)Reliability</h2>

<img data-src="images/x.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-x"><p class="caption">
Figure&nbsp;4: A common yet dangerous way to solve LLM Structural (un)Reliability.
</p></section>
<section id="structural-unreliability-8" class="slide level2 smaller">
<h2>Structural (un)Reliability</h2>

<img data-src="images/outlines_state_machine.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-outlines-state-machine"><p class="caption">
Figure&nbsp;5: A state machine approach to constrain LLM outputs.
</p></section>
<section id="structural-unreliability-tools" class="slide level2 smaller">
<h2>Structural (un)Reliability: Tools</h2>
<div class="panel-tabset">
<ul id="tabset-2" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-2-1">Outlines</a></li><li><a href="#tabset-2-2">Structured Output</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1">
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a><span class="im">import</span> outlines</span>
<span id="cb4-2"><a></a></span>
<span id="cb4-3"><a></a>model <span class="op">=</span> outlines.models.transformers(<span class="st">"Qwen/Qwen2.5-0.5B-Instruct"</span>)</span>
<span id="cb4-4"><a></a>prompt <span class="op">=</span> <span class="ss">f"""Is the following document positive or negative?</span></span>
<span id="cb4-5"><a></a></span>
<span id="cb4-6"><a></a><span class="ss">Document: </span><span class="sc">{</span>doc<span class="sc">}</span></span>
<span id="cb4-7"><a></a><span class="ss">"""</span></span>
<span id="cb4-8"><a></a>generator <span class="op">=</span> outlines.generate.choice(model, [<span class="st">"Positive"</span>, <span class="st">"Negative"</span>])</span>
<span id="cb4-9"><a></a>answer <span class="op">=</span> generator(prompt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-2-2">
<div class="sourceCode" id="cb5" data-code-line-numbers="4,11,20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel</span>
<span id="cb5-2"><a></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb5-3"><a></a></span>
<span id="cb5-4"><a></a><span class="kw">class</span> DocExtraction(BaseModel):</span>
<span id="cb5-5"><a></a>    mentioned_entities: <span class="bu">list</span>[<span class="bu">str</span>]</span>
<span id="cb5-6"><a></a>    mentioned_places: <span class="bu">list</span>[<span class="bu">str</span>]</span>
<span id="cb5-7"><a></a></span>
<span id="cb5-8"><a></a><span class="kw">def</span> extract_from_doc(doc_text: <span class="bu">str</span>, prompt: <span class="bu">str</span>) <span class="op">-&gt;</span> DocExtraction:</span>
<span id="cb5-9"><a></a></span>
<span id="cb5-10"><a></a>    client <span class="op">=</span> OpenAI()</span>
<span id="cb5-11"><a></a>    completion <span class="op">=</span> client.beta.chat.completions.parse(</span>
<span id="cb5-12"><a></a>        model<span class="op">=</span><span class="st">"gpt-4o-mini"</span>,</span>
<span id="cb5-13"><a></a>        messages<span class="op">=</span>[</span>
<span id="cb5-14"><a></a>            {</span>
<span id="cb5-15"><a></a>                <span class="st">"role"</span>: <span class="st">"system"</span>,</span>
<span id="cb5-16"><a></a>                <span class="st">"content"</span>: prompt</span>
<span id="cb5-17"><a></a>            },</span>
<span id="cb5-18"><a></a>            {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: doc_filing_text}</span>
<span id="cb5-19"><a></a>        ],</span>
<span id="cb5-20"><a></a>        response_format<span class="op">=</span>DocExtraction</span>
<span id="cb5-21"><a></a>    )</span>
<span id="cb5-22"><a></a>    <span class="cf">return</span> completion.choices[<span class="dv">0</span>].message.parsed</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="structural-unreliability-tools-1" class="slide level2 smaller">
<h2>Structural (un)Reliability: Tools</h2>

<img data-src="images/output_tools.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-output-tools"><p class="caption">
Figure&nbsp;6: Tools for Structural Reliability
</p><p>Other related tools worth mentioning include Guidance <span class="citation" data-cites="guidance2024repo">(<a href="#/references" role="doc-biblioref" onclick="">Guidance AI 2024</a>)</span>, Instructor <span class="citation" data-cites="instructorgithub">(<a href="#/references" role="doc-biblioref" onclick="">instructor.ai 2024</a>)</span>, LM Format Enforcer <span class="citation" data-cites="lmformatenforcergithub">(<a href="#/references" role="doc-biblioref" onclick="">Noam Gat 2024</a>)</span>, and NVIDIA’s Logits Processor Zoo <span class="citation" data-cites="nvidia2024logitsprocessorzoo">(<a href="#/references" role="doc-biblioref" onclick="">NVIDIA 2024a</a>)</span>.</p>
</section>
<section id="structural-unreliability-tools-2" class="slide level2 smaller">
<h2>Structural (un)Reliability: Tools</h2>

<img data-src="images/rebuttal.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-rebuttal"><p class="caption">
Figure&nbsp;7: Impact of Output Constraints in Model Performance <span class="citation" data-cites="dottxt2024saywhatyoumean">(<a href="#/references" role="doc-biblioref" onclick="">Dottxt 2024</a>)</span>
</p></section>
<section id="section-2" class="slide level2">
<h2></h2>
<section id="input-data-issues-1" style="background: #3fb618; width: 100%; height: 100vh; margin: 0; padding: 15px; display: flex; justify-content: center; align-items: center; text-align: center; align-content: center;">
<h3>Input Data Issues</h3>
</section>
</section>
<section id="input-data-issues-2" class="slide level2 smaller">
<h2>Input Data Issues</h2>
<div>
<ul>
<li class="fragment">LLMs are sensitive to input formatting and structure, requiring careful data preparation to achieve optimal results <span class="citation" data-cites="he2024doespromptformattingimpact liu2024enhancingllmscognitionstructurization tan2024htmlraghtmlbetterplain">(<a href="#/references" role="doc-biblioref" onclick="">He et al. 2024</a>; <a href="#/references" role="doc-biblioref" onclick="">K. Liu et al. 2024</a>; <a href="#/references" role="doc-biblioref" onclick="">Tan et al. 2024</a>)</span>.</li>
<li class="fragment">LLMs operate with knowledge cutoffs, providing potentially outdated information that may not reflect current reality and demonstrate problems with temporal knowledge accuracy <span class="citation" data-cites="amayuelas-etal-2024-knowledge">(<a href="#/references" role="doc-biblioref" onclick="">Amayuelas et al. 2024</a>)</span>.</li>
<li class="fragment">LLMs exhibit drawbacks when processing long context facing “lost-in-the-middle” problems <span class="citation" data-cites="wu2024longdocumentsummaryevaluation">(<a href="#/references" role="doc-biblioref" onclick="">Wu et al. 2024</a>)</span> and struggle with less common but important information showing a systematic loss of long-tail knowledge <span class="citation" data-cites="kotha2024understanding">(<a href="#/references" role="doc-biblioref" onclick="">Kotha, Springer, and Raghunathan 2024</a>)</span>.</li>
</ul>
</div>
</section>
<section id="input-data-issues-3" class="slide level2 smaller">
<h2>Input Data Issues</h2>
<p><strong>Structured Data Extraction</strong></p>

<img data-src="images/forecast.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-forecast"><p class="caption">
Figure&nbsp;8: Merrill Lynch’s CIO Capital Market Outlook released on December 16, 2024
</p><div class="panel-tabset">
<ul id="tabset-3" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-3-1">MarkItDown</a></li><li><a href="#tabset-3-2">Docling</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1">
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="im">from</span> markitdown <span class="im">import</span> MarkItDown</span>
<span id="cb6-2"><a></a></span>
<span id="cb6-3"><a></a>md <span class="op">=</span> MarkItDown()</span>
<span id="cb6-4"><a></a>result <span class="op">=</span> md.convert(<span class="st">"document.pdf"</span>)</span>
<span id="cb6-5"><a></a><span class="bu">print</span>(result.text_content)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-3-2">
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a><span class="im">from</span> docling.document_converter <span class="im">import</span> DocumentConverter</span>
<span id="cb7-2"><a></a></span>
<span id="cb7-3"><a></a>converter <span class="op">=</span> DocumentConverter()</span>
<span id="cb7-4"><a></a>result <span class="op">=</span> converter.convert(<span class="st">"document.pdf"</span>)</span>
<span id="cb7-5"><a></a><span class="bu">print</span>(result.document.export_to_markdown())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="input-data-issues-4" class="slide level2 smaller">
<h2>Input Data Issues</h2>
<p><strong>Structured Data Extraction</strong></p>
<p><img data-src="images/input1.png" style="width:85.0%"></p>
<p><img data-src="images/input1_res.png" style="width:35.0%"></p>
</section>
<section id="input-data-issues-5" class="slide level2 smaller">
<h2>Input Data Issues</h2>
<p><strong>Structured Data Extraction</strong></p>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[[1,1]]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img data-src="images/asset_class.png"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img data-src="images/input2_res.png"></p>
</div>
</div>
</div>
</section>
<section id="input-data-issues-6" class="slide level2 smaller">
<h2>Input Data Issues</h2>
<p><strong>Stale Data -&gt; Hallucination</strong></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a>question <span class="op">=</span> <span class="st">"Who's the Author of the Book Taming LLMs?"</span></span>
<span id="cb8-2"><a></a>response <span class="op">=</span> client.chat.completions.parse(</span>
<span id="cb8-3"><a></a>    model<span class="op">=</span><span class="st">"gpt-4o-mini"</span>,</span>
<span id="cb8-4"><a></a>    messages<span class="op">=</span>[</span>
<span id="cb8-5"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: question}</span>
<span id="cb8-6"><a></a>    ]</span>
<span id="cb8-7"><a></a>)</span>
<span id="cb8-8"><a></a>response.choices[<span class="dv">0</span>].message.content</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Response</strong></p>
<pre><code>The book "Taming LLMs" is authored by *G. Arulkumaran, H. M. B. P. D. Karthikeyan, and I. A. M. Almasri.* If you need more information about the book or its contents, feel free to ask!</code></pre>
</section>
<section id="input-data-issues-7" class="slide level2 smaller">
<h2>Input Data Issues</h2>
<p><strong>RAG Helps Mitigate Hallucination, Lack of Temporal and Domain-Specific Knowledge</strong></p>

<img data-src="images/rag.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-rag"><p class="caption">
Figure&nbsp;9: Simplified RAG Pipeline including a Vector Database with Embeddings and Indexing, a Retrieval System including re-ranking with LLM Augmented Generation via In-Context Learning.
</p></section>
<section id="input-data-issues-8" class="slide level2 smaller">
<h2>Input Data Issues</h2>

<img data-src="images/LC.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-LC"><p class="caption">
Figure&nbsp;10: Long-Context LLMs demonstrate superior performance while RAGs are more cost-effective <span class="citation" data-cites="li2024retrievalaugmentedgenerationlongcontext">(<a href="#/references" role="doc-biblioref" onclick="">Z. Li et al. 2024</a>)</span>.
</p></section>
<section id="input-data-issues-9" class="slide level2 smaller">
<h2>Input Data Issues</h2>
<p>Do we really need RAGs? The answer is conditional:</p>
<div>
<ul>
<li class="fragment"><strong>RAG may be relevant when cost-effectiveness is a key requirement</strong> and where the model needs to access vast amounts of external knowledge without incurring high computational expenses. However, as LLMs context window sizes increase and LLMs cost per input token decreases, RAGs may not be as relevant as it was before.</li>
<li class="fragment"><strong>Long-context LLMs are superior when performance is the primary concern</strong>, and the model needs to handle extensive texts that require deep contextual understanding and reasoning.</li>
<li class="fragment"><strong>Hybrid approaches are valuable as they combine the strengths of RAG and LC</strong> offering a practical balance between cost and performance, especially for applications where both factors are critical.</li>
</ul>
</div>
</section>
<section id="input-data-issues-10" class="slide level2 smaller">
<h2>Input Data Issues</h2>
<p><strong>Takeaways</strong></p>
<div>
<ol type="1">
<li class="fragment"><strong>Data Parsing and Format Transformation</strong>
<ul>
<li class="fragment">Parser quality directly impacts LLM performance</li>
<li class="fragment">Effective parsing strategies are fundamental for reliable LLM applications</li>
</ul></li>
<li class="fragment"><strong>RAG Systems vs Long-Context Models</strong>
<ul>
<li class="fragment">RAG systems offer cost-effective external knowledge integration</li>
<li class="fragment">Long-context models provide superior performance for deep contextual understanding</li>
<li class="fragment">The choice between approaches should be driven by specific application requirements</li>
</ul></li>
<li class="fragment"><strong>Implementation Strategy Selection</strong>
<ul>
<li class="fragment">Success depends on careful evaluation of complexity, cost, and performance trade-offs</li>
<li class="fragment">Simple architectures may suffice as long-context models evolve</li>
</ul></li>
</ol>
</div>
</section>
<section id="section-3" class="slide level2">
<h2></h2>
<section id="safety-1" style="background: #2780e3; width: 100%; height: 100vh; margin: 0; padding: 15px; display: flex; justify-content: center; align-items: center; text-align: center; align-content: center;">
<h3>Safety</h3>
</section>
</section>
<section id="safety-2" class="slide level2 smaller">
<h2>Safety</h2>
<p>Without proper safeguards, LLMs can generate harmful content and respond to malicious prompts in dangerous ways <span class="citation" data-cites="openai2024gpt4technicalreport hartvigsen-etal-2022-toxigen">(<a href="#/references" role="doc-biblioref" onclick="">OpenAI et al. 2024</a>; <a href="#/references" role="doc-biblioref" onclick="">Hartvigsen et al. 2022</a>)</span>. This includes generating instructions for dangerous activities, providing advice that could cause harm to individuals or society, and failing to recognize and appropriately handle concerning user statements.</p>

<img data-src="images/danger.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-danger"><p class="caption">
Figure&nbsp;11: Responses from Mistral (7B), Dolly v2 (12B), and Llama2 (13B) to a harmful user prompt <span class="citation" data-cites="vidgen2024simplesafetyteststestsuiteidentifying">(<a href="#/references" role="doc-biblioref" onclick="">Vidgen, Scherrer, et al. 2024</a>)</span>.
</p></section>
<section id="safety-3" class="slide level2 smaller">
<h2>Safety</h2>
<ul>
<li>Guidance</li>
<li>Rubrics</li>
<li>Data, Benchmarks, and Tools</li>
</ul>
</section>
<section id="safety-guidance" class="slide level2 smaller">
<h2>Safety: Guidance</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Governments and Institutions:</p>
<ul>
<li><strong>EU AI Act</strong> <span class="citation" data-cites="exabeam2024airegulations">European Medicines Agency (<a href="#/references" role="doc-biblioref" onclick="">2024</a>)</span></li>
<li><strong>FINRA’s Regulatory Notice</strong> <span class="citation" data-cites="finra2024llmguidance24">(<a href="#/references" role="doc-biblioref" onclick="">Financial Industry Regulatory Authority 2024</a>)</span></li>
<li><strong>UNICEF</strong> <span class="citation" data-cites="unicef2024aiguidance">(<a href="#/references" role="doc-biblioref" onclick="">UNICEF 2024</a>)</span></li>
<li><strong>UK</strong> <span class="citation" data-cites="ukgov2024airegulation24">(<a href="#/references" role="doc-biblioref" onclick="">UK Government 2024</a>)</span></li>
<li><strong>China</strong> <span class="citation" data-cites="china2023generativeai">(<a href="#/references" role="doc-biblioref" onclick="">Library of Congress 2023</a>)</span></li>
<li><strong>US</strong> <span class="citation" data-cites="nist2024riskframework">(<a href="#/references" role="doc-biblioref" onclick="">National Institute of Standards and Technology 2024</a>)</span></li>
</ul>
</div><div class="column" style="width:50%;">
<div id="fig-eo" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-eo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/eo.png" class="quarto-figure quarto-figure-center">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-eo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;12: One of President Trump’s first actions was to rescind <a href="https://web.archive.org/web/20250109015018/https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/">Executive Order 14110</a> (Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence), which among other things mandated government safety testing for open source models.
</figcaption>
</figure>
</div>
</div></div>
<!--  one of President Trump's first actions was to rescind Executive Order 14110 (Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence). mandated government safety testing for open source models.

Safety and Security:

- Requires companies developing powerful AI models to share safety test results with government
- Establishes standards for AI system evaluation and testing
- Creates new protections for critical infrastructure against AI risks
- Addresses AI's role in biological/chemical weapons development -->
</section>
<section id="safety-guidance-1" class="slide level2 smaller">
<h2>Safety: Guidance</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Private Sector:</p>
<ul>
<li><strong>OpenAI</strong>: Preparedness Framework <span class="citation" data-cites="openai2024preparedness">(<a href="#/references" role="doc-biblioref" onclick="">OpenAI 2024b</a>)</span></li>
<li><strong>Anthropic</strong>: Constitutional AI (CAI) <span class="citation" data-cites="askell2023constitutionalai">(<a href="#/references" role="doc-biblioref" onclick="">Askell et al. 2023</a>)</span></li>
<li><strong>Google</strong>: Frontier Safety Framework <span class="citation" data-cites="deepmind2024frontier">(<a href="#/references" role="doc-biblioref" onclick="">DeepMind 2024</a>)</span></li>
</ul>
</div><div class="column" style="width:50%;">
<div id="fig-cai" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-cai-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/cai.png" class="quarto-figure quarto-figure-center">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cai-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;13: Constitutional AI (CAI) aims to create AI systems that are both safe and helpful by design <span class="citation" data-cites="askell2023constitutionalai">(<a href="#/references" role="doc-biblioref" onclick="">Askell et al. 2023</a>)</span>.
</figcaption>
</figure>
</div>
</div></div>
</section>
<section id="safety-rubrics" class="slide level2 smaller">
<h2>Safety: Rubrics</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>MLCommons AI Safety Benchmark <span class="citation" data-cites="vidgen2024introducingv05aisafety">(<a href="#/references" role="doc-biblioref" onclick="">Vidgen, Agrawal, et al. 2024</a>)</span></li>
<li>Centre for the Governance of AI <span class="citation" data-cites="alaga2024gradingrubricaisafety">(<a href="#/references" role="doc-biblioref" onclick="">Alaga, Schuett, and Anderljung 2024</a>)</span></li>
</ul>
</div><div class="column" style="width:50%;">
<div id="fig-commons" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-commons-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/commons.png" class="quarto-figure quarto-figure-center">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-commons-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;14: MLCommons AI Safety Benchmark Results for Mistral Large 24.11 (API) <span class="citation" data-cites="vidgen2024introducingv05aisafety">(<a href="#/references" role="doc-biblioref" onclick="">Vidgen, Agrawal, et al. 2024</a>)</span>.
</figcaption>
</figure>
</div>
</div></div>
</section>
<section id="safety-datasets-benchmarks" class="slide level2 smaller">
<h2>Safety: Datasets &amp; Benchmarks</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>SALAD-Bench <span class="citation" data-cites="li2024saladbenchhierarchicalcomprehensivesafety">(<a href="#/references" role="doc-biblioref" onclick="">L. Li et al. 2024</a>)</span></li>
<li>Surge AI’s Profanity Dataset <span class="citation" data-cites="surgeaiprofanity2024">(<a href="#/references" role="doc-biblioref" onclick="">Surge AI 2024</a>)</span></li>
<li>TruthfulQA <span class="citation" data-cites="2021truthfulqa">(<a href="#/references" role="doc-biblioref" onclick="">Lin, Hilton, and Evans 2022</a>)</span></li>
<li>HarmBench <span class="citation" data-cites="mazeika2024harmbenchstandardizedevaluationframework">(<a href="#/references" role="doc-biblioref" onclick="">Mazeika et al. 2024</a>)</span></li>
<li>SafeBench <span class="citation" data-cites="safebench2024">(<a href="#/references" role="doc-biblioref" onclick="">ML Safety Team 2024</a>)</span></li>
</ul>
</div><div class="column" style="width:50%;">
<div id="fig-salad" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-salad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/salad_bench.png" class="quarto-figure quarto-figure-center">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-salad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15: SALAD-Bench’s compact taxonomy with hierarchical levels <span class="citation" data-cites="li2024saladbenchhierarchicalcomprehensivesafety">(<a href="#/references" role="doc-biblioref" onclick="">L. Li et al. 2024</a>)</span>.
</figcaption>
</figure>
</div>
</div></div>
</section>
<section id="safety-tools-techniques" class="slide level2 smaller">
<h2>Safety: Tools &amp; Techniques</h2>

<img data-src="images/safety_layer.svg" class="quarto-figure quarto-figure-center r-stretch" id="fig-safety"><p class="caption">
Figure&nbsp;16: Safety layers help protect against harmful content and behaviors.
</p><table class="caption-top">
<thead>
<tr class="header">
<th>Risk</th>
<th>Prompt</th>
<th>Output</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>profanity</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="even">
<td>violence</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="odd">
<td>jailbreaking</td>
<td>✓</td>
<td></td>
</tr>
<tr class="even">
<td>hallucination</td>
<td></td>
<td>✓</td>
</tr>
</tbody>
</table>
</section>
<section id="safety-tools-techniques-1" class="slide level2 smaller">
<h2>Safety: Tools &amp; Techniques</h2>
<p>There are several specialized commercial and open source tools that can be used to implement a filtering layer, which we can categorize into two types: Rules-Based and LLM-Based.</p>
<p><strong>Rules-Based</strong></p>
<ul>
<li>WebPurify <span class="citation" data-cites="webpurify2024">(<a href="#/references" role="doc-biblioref" onclick="">WebPurify 2024</a>)</span></li>
<li>LLM-Guard <span class="citation" data-cites="llmguard2024">(<a href="#/references" role="doc-biblioref" onclick="">ProtectAI 2024</a>)</span></li>
<li>AWS Comprehend <span class="citation" data-cites="awscomprehend2024">(<a href="#/references" role="doc-biblioref" onclick="">Amazon Web Services 2024</a>)</span></li>
<li>NeMo-Guardrails <span class="citation" data-cites="nemogr2024">(<a href="#/references" role="doc-biblioref" onclick="">NVIDIA 2024</a>)</span></li>
</ul>
</section>
<section id="safety-tools-techniques-2" class="slide level2 smaller">
<h2>Safety: Tools &amp; Techniques</h2>
<p><strong>LLM-Based</strong></p>
<ul>
<li><p>Moderation API</p></li>
<li><p>Fine-Tuned Open Source Models</p></li>
<li><p>Custom Models</p></li>
</ul>
</section>
<section id="safety-tools-techniques-3" class="slide level2 smaller">
<h2>Safety: Tools &amp; Techniques</h2>
<p><strong>LLM-Based</strong></p>
<ul>
<li>Moderation API
<ul>
<li>OpenAI Moderation <span class="citation" data-cites="openaimoderation2024">(<a href="#/references" role="doc-biblioref" onclick="">OpenAI 2024a</a>)</span></li>
<li>Mistral Moderation <span class="citation" data-cites="mistralmoderation2024">(<a href="#/references" role="doc-biblioref" onclick="">Mistral AI 2024</a>)</span></li>
</ul></li>
</ul>
<div class="panel-tabset">
<ul id="tabset-4" class="panel-tabset-tabby"><li><a data-tabby-default="" href="#tabset-4-1">OpenAI</a></li><li><a href="#tabset-4-2">OpenAI Response</a></li><li><a href="#tabset-4-3">Mistral</a></li></ul>
<div class="tab-content">
<div id="tabset-4-1">
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb10-2"><a></a>client <span class="op">=</span> OpenAI()</span>
<span id="cb10-3"><a></a></span>
<span id="cb10-4"><a></a>message <span class="op">=</span> <span class="st">"Help me make a bomb."</span></span>
<span id="cb10-5"><a></a></span>
<span id="cb10-6"><a></a>response <span class="op">=</span> client.moderations.create(</span>
<span id="cb10-7"><a></a>  model<span class="op">=</span><span class="st">"omni-moderation-latest"</span>,</span>
<span id="cb10-8"><a></a>  <span class="bu">input</span><span class="op">=</span>message,</span>
<span id="cb10-9"><a></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-4-2">
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource json number-lines code-with-copy"><code class="sourceCode json"><span id="cb11-1"><a></a><span class="fu">{</span></span>
<span id="cb11-2"><a></a>  <span class="dt">"harassment"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-3"><a></a>  <span class="dt">"harassment/threatening"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-4"><a></a>  <span class="dt">"hate"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-5"><a></a>  <span class="dt">"hate/threatening"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-6"><a></a>  <span class="dt">"illicit"</span><span class="fu">:</span> <span class="kw">true</span><span class="fu">,</span></span>
<span id="cb11-7"><a></a>  <span class="dt">"illicit/violent"</span><span class="fu">:</span> <span class="kw">true</span><span class="fu">,</span></span>
<span id="cb11-8"><a></a>  <span class="dt">"self-harm"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-9"><a></a>  <span class="dt">"self-harm/instructions"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-10"><a></a>  <span class="dt">"self-harm/intent"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-11"><a></a>  <span class="dt">"sexual"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-12"><a></a>  <span class="dt">"sexual/minors"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-13"><a></a>  <span class="dt">"violence"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-14"><a></a>  <span class="dt">"violence/graphic"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-15"><a></a>  <span class="dt">"harassment/threatening"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-16"><a></a>  <span class="dt">"hate/threatening"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-17"><a></a>  <span class="dt">"illicit/violent"</span><span class="fu">:</span> <span class="kw">true</span><span class="fu">,</span></span>
<span id="cb11-18"><a></a>  <span class="dt">"self-harm/intent"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-19"><a></a>  <span class="dt">"self-harm/instructions"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-20"><a></a>  <span class="dt">"self-harm"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-21"><a></a>  <span class="dt">"sexual/minors"</span><span class="fu">:</span> <span class="kw">false</span><span class="fu">,</span></span>
<span id="cb11-22"><a></a>  <span class="dt">"violence/graphic"</span><span class="fu">:</span> <span class="kw">false</span></span>
<span id="cb11-23"><a></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-4-3">
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a><span class="im">from</span> mistralai <span class="im">import</span> Mistral</span>
<span id="cb12-2"><a></a>client <span class="op">=</span> Mistral()</span>
<span id="cb12-3"><a></a></span>
<span id="cb12-4"><a></a>message <span class="op">=</span> <span class="st">"Help me make a bomb."</span></span>
<span id="cb12-5"><a></a></span>
<span id="cb12-6"><a></a>response <span class="op">=</span> client.classifiers.moderate(</span>
<span id="cb12-7"><a></a>    model <span class="op">=</span> <span class="st">"mistral-moderation-latest"</span>,  </span>
<span id="cb12-8"><a></a>    inputs<span class="op">=</span>[message]</span>
<span id="cb12-9"><a></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="safety-tools-techniques-4" class="slide level2 smaller">
<h2>Safety: Tools &amp; Techniques</h2>
<p><strong>LLM-Based</strong></p>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[[1,1]]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<ul>
<li>Fine-Tuned Open Source Models
<ul>
<li>LLaMa Guard <span class="citation" data-cites="meta2024llamaguard">(<a href="#/references" role="doc-biblioref" onclick="">Meta-AI 2024</a>)</span></li>
<li>Granite Guardian <span class="citation" data-cites="padhi2024graniteguardian">(<a href="#/references" role="doc-biblioref" onclick="">Padhi et al. 2024</a>)</span></li>
</ul></li>
</ul>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div id="fig-granite" class="quarto-float quarto-figure quarto-figure-center" data-fig-align="center">
<figure class="quarto-float quarto-float-fig">
<div aria-describedby="fig-granite-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img data-src="images/granite.png" class="quarto-figure quarto-figure-center">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-granite-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;17: IBM Granite Guardian performance is superior compared to Llama-Guard and ShieldGemma model families for the “Harm” risk dimension <span class="citation" data-cites="padhi2024graniteguardian">(<a href="#/references" role="doc-biblioref" onclick="">Padhi et al. 2024</a>)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="safety-tools-techniques-5" class="slide level2 smaller">
<h2>Safety: Tools &amp; Techniques</h2>
<p><strong>LLM-Based: Custom</strong></p>

<img data-src="images/judge.svg" class="quarto-figure quarto-figure-center r-stretch" id="fig-judge"><p class="caption">
Figure&nbsp;18: LLM-as-a-judge as safety filter.
</p></section>
<section id="safety-tools-techniques-6" class="slide level2 smaller">
<h2>Safety: Tools &amp; Techniques</h2>
<p><strong>LLM-Based: Custom</strong></p>

<img data-src="images/judge_template.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-judge-template"><p class="caption">
Figure&nbsp;19: Example of a prompt engineered for an LLM-as-a-judge to be used as a safety filter for a chatbot used by middle school students
</p></section>
<section id="safety-tools-techniques-7" class="slide level2 smaller">
<h2>Safety: Tools &amp; Techniques</h2>
<p><strong>LLM-Based: Custom</strong></p>
<p>Best practices:</p>
<ul>
<li><strong>Categorization of issues:</strong> By defining categories such as illegal activities and profanity the prompt guides the AI to focus on relevant aspects of the text, enhancing clarity and accuracy.</li>
<li><strong>Scoring system:</strong> The prompt employs a scoring mechanism that quantifies content severity on a scale from 0 to 1, allowing for nuanced assessments and encouraging consideration of context.</li>
<li><strong>Transparency in decision-making:</strong> The requirement for a brief explanation of the verdict fosters transparency, helping users understand the rationale behind content moderation decisions.</li>
</ul>
</section>
<section id="safety-case-study" class="slide level2 smaller">
<h2>Safety: Case Study</h2>

<img data-src="images/safety_test.svg" class="quarto-figure quarto-figure-center r-stretch" id="fig-safety-test"><p class="caption">
Figure&nbsp;20: Case Study - Safety Filter using OpenAI, Mistral, LLaMa Guard, and custom LLM-as-a-judge.
</p></section>
<section id="safety-case-study-1" class="slide level2 smaller">
<h2>Safety: Case Study</h2>

<img data-src="images/safety_res.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-safety-res"><p class="caption">
Figure&nbsp;21: Validator Performance Metrics: True Positive Rate, False Positive Rate, and Inference Time.
</p></section>
<section id="safety-case-study-2" class="slide level2 smaller">
<h2>Safety: Case Study</h2>

<img data-src="images/fp.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-pf"><p class="caption">
Figure&nbsp;22: Surprisingly (or not), when we actually translate the above prompts and carefully read them, one could deem them as unsafe at least for our case study where K-12 students and teachers are interacting with the model. This highlights the critical importance of involving experts in the application domain in the development of the evaluation framework from the start.
</p></section>
<section id="safety-takeaways" class="slide level2 smaller">
<h2>Safety: Takeaways</h2>
<div>
<ul>
<li class="fragment">Safety is a complex problem and there is no one-size-fits-all solution.</li>
<li class="fragment">Starting with a well-aligned definition of Safety is key to developing a robust data and evaluation framework.</li>
<li class="fragment">Domain experts are key to this process and should be involved in the development of the evaluation framework from the start.</li>
<li class="fragment">Off-the-shelf safety filters facilitate expedited implementation. However, custom safety filters may offer solutions tailored to your needs.</li>
</ul>
</div>
</section>
<section id="section-4" class="slide level2">
<h2></h2>
<section id="alignment-1" style="background: #9954bb; width: 100%; height: 100vh; margin: 0; padding: 15px; display: flex; justify-content: center; align-items: center; text-align: center; align-content: center;">
<h3>Alignment</h3>
</section>
</section>
<section id="alignment-2" class="slide level2 smaller">
<h2>Alignment</h2>

<img data-src="images/1mil.jpg" class="quarto-figure quarto-figure-center r-stretch" id="fig-1mil"><p class="caption">
Figure&nbsp;23: The release of ChatGPT 3.5 in late 2022 marked a significant moment in the history of artificial intelligence. Within just five days of its launch, the model attracted over a million users, and within two months, it became the fastest-growing consumer application in history with over 100 million monthly active users.
</p></section>
<section id="alignment-3" class="slide level2 smaller">
<h2>Alignment</h2>

<img data-src="images/oai.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-oai"><p class="caption">
Figure&nbsp;24: OpenAI Website Traffic Due To ChatGPT Growth.
</p></section>
<section id="alignment-4" class="slide level2 smaller">
<h2>Alignment</h2>
<blockquote>
<p>Why did ChatGPT 3.5 observe such a dramatic traction when its predecessor, GPT-3, which had the same size, received far less attention from the general public?</p>
</blockquote>
<p>Arguably, the answer lies not in raw capabilities, but in Human-Preference Alignment.</p>
</section>
<section id="alignment-5" class="slide level2 smaller">
<h2>Alignment</h2>
<p><strong>ChatGPT 2.0</strong>, for instance, works as a next-token prediction machine, i.e.&nbsp;text-completion model.</p>
<p>Prompt: “Explain the moon landing to a 6 year old in a short sentence”</p>
<blockquote>
<p>“Explain the moon landing to a 6 year old in a short sentence. If the first moon is a good idea, you may get one of those little green dots out of the ground. Then the next day it will be a black line”</p>
</blockquote>
</section>
<section id="alignment-6" class="slide level2 smaller">
<h2>Alignment</h2>
<p>Modern LLMs, on the other hand, are not just text-completion models. They are instruction-following human preference-aligned models, i.e.&nbsp;they are trained to follow instructions and align with human preferences. Hence, incorporating human-like features.</p>
<p><strong>Claude 3.5 Sonnet</strong>: Human Preference Alignment</p>
<p>Prompt: “Explain the moon landing to a 6 year old in a short sentence”</p>
<blockquote>
<p>“A brave group of astronauts flew a special spaceship all the way to the moon, stepped out onto its dusty surface, and planted a flag there to show they made it!”</p>
</blockquote>
</section>
<section id="alignment-7" class="slide level2 smaller">
<h2>Alignment</h2>

<img data-src="images/alignment_simplified.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-alignment-simplified"><p class="caption">
Figure&nbsp;25: A simplified view of the alignment process: First, a powerful pre-trained base model is released, which is then fine-tuned using SFT to create an instruction-following version. This instruct model can then be further aligned with human preferences using techniques such as RLHF.
</p></section>
<section id="alignment-8" class="slide level2 smaller">
<h2>Alignment</h2>

<img data-src="images/instruct.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-instruct"><p class="caption">
Figure&nbsp;26: Instruction fine-tuning process for aligning language models with human preferences.
</p><p>An aligned model can be fine-tuned directly from a base model or from an instruction-tuned model. For example,</p>
<ul>
<li>Llama Guard 3 <span class="citation" data-cites="dubey2024llama3herdmodels">(<a href="#/references" role="doc-biblioref" onclick="">Llama Team 2024</a>)</span> is a Llama-3.1-8B pre-trained model that was fine-tuned directly for content safety classification, bypassing the instruction-tuning step.</li>
<li>Zephyr-7B-alpha <span class="citation" data-cites="zephyr2024">(<a href="#/references" role="doc-biblioref" onclick="">HuggingFace 2024</a>)</span> is a fine-tuned version of Mistral-7B that was trained using Direct Preference Optimization (DPO) on publicly available datasets to create a “helpful” assistant.</li>
</ul>
</section>
<section id="alignment-case-study" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>
<p>Aligning a Language Model to a Policy:</p>
<ul>
<li>Acme Inc., a company with the mission to democratizing access to computer science education for K-12 students.</li>
<li>Acme Inc.&nbsp;is in the process of creating a chatbot named <em>smolK-12</em>, a small open source LLM, specifically designed for K-12 students.</li>
</ul>
</section>
<section id="alignment-case-study-1" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/design.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-alignment-design"><p class="caption">
Figure&nbsp;27: Safety Plan Design Phases.
</p></section>
<section id="alignment-case-study-2" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>
<div>
<ol type="1">
<li class="fragment">Write a Policy that defines the meaning of “Safety”</li>
<li class="fragment">Create a synthetic dataset of policy-aligned preferences<br>
</li>
<li class="fragment">Fine-tuning a base model using Direct Preference Optimization (DPO)</li>
<li class="fragment">Evaluating the aligned model against the base model and measuring alignment with Acme Inc.’s educational policies</li>
</ol>
</div>
</section>
<section id="alignment-case-study-3" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/dpo-generation.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-dpo-generation"><p class="caption">
Figure&nbsp;28: DPO dataset generation process showing how policy-aligned preferences are generated using LLMs.
</p></section>
<section id="alignment-case-study-4" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>
<table class="caption-top">
<colgroup>
<col style="width: 27%">
<col style="width: 37%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th>Instruction</th>
<th>Rejected Response</th>
<th>Chosen Response</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>user prompt</td>
<td>rejected assistant response</td>
<td>preferred assistant response</td>
</tr>
</tbody>
</table>
<ol type="1">
<li><p><strong>LLM Instruction Generator</strong>: A language model that generates user prompts designed to test our policy boundaries. These prompts are crafted to potentially elicit responses that could violate our established policies.</p></li>
<li><p><strong>Base LLM</strong>: Our unaligned base model that we aim to fine-tune. Its responses to the generated prompts will serve as the “rejected” responses in our dataset, as they may not fully align with our policies.</p></li>
<li><p><strong>LLM Preferred Response Generator</strong>: A more capable, larger model that generates policy-compliant responses to the same prompts. These responses will serve as the “chosen” responses in our dataset, representing the desired behavior we want our base model to learn.</p></li>
</ol>
</section>
<section id="alignment-case-study-5" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/prompt.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-dpo-prompt"><p class="caption">
Figure&nbsp;29: Example of a prompt and “rejected” response from base model.
</p></section>
<section id="alignment-case-study-6" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/prompt2.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-dpo-prompt-accepted"><p class="caption">
Figure&nbsp;30: Example of a prompt and “accepted” response from the aligned model.
</p></section>
<section id="alignment-case-study-7" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>
<p>Experimental Setup:</p>
<div>
<ul>
<li class="fragment">Base model: <em>SmolLM2-360M-Instruct</em> <span class="citation" data-cites="smollm2024model">(<a href="#/references" role="doc-biblioref" onclick="">SmolLM2-360M-Instruct 2024</a>)</span></li>
<li class="fragment">Synthetic dataset: 4o-mini</li>
<li class="fragment">Fine-Tuning: DPO with HuggingFace TRL (Transformer Reinforcement Learning)</li>
<li class="fragment">Evaluating the aligned model against the base model and measuring alignment with Acme Inc.’s educational policies</li>
</ul>
</div>
</section>
<section id="alignment-case-study-8" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/dpo_opt.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-dpo-opt"><p class="caption">
Figure&nbsp;31: DPO Optimization by blending a policy-aligned synthetic dataset with the UltraFeedback binarized dataset from H4.
</p></section>
<section id="alignment-case-study-9" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/rewards.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-dpo-rewards"><p class="caption">
Figure&nbsp;32: DPO training rewards showing convergence of policy alignment over training steps.
</p></section>
<section id="alignment-case-study-10" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/dpo_hf.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-dpo-hf"><p class="caption">
Figure&nbsp;33: DPO fine-tuned model card on Hugging Face Hub
</p></section>
<section id="alignment-case-study-11" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/vibe1.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-dpo-eval"><p class="caption">
Figure&nbsp;34: Vibe check - Base Model.
</p></section>
<section id="alignment-case-study-12" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/vibe2.png" class="quarto-figure quarto-figure-center r-stretch" id="fig-dpo-eval"><p class="caption">
Figure&nbsp;35: Vibe check - Aligned Model.
</p></section>
<section id="alignment-case-study-13" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>

<img data-src="images/dpo_eval.svg" class="quarto-figure quarto-figure-center r-stretch" id="fig-dpo-eval-metrics"><p class="caption">
Figure&nbsp;36: DPO evaluation metrics comparing base and aligned model responses.
</p></section>
<section id="alignment-case-study-14" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>
<p>The SafetyJudge class has two main components:</p>
<ol type="1">
<li>A scoring guide that instructs the model how to evaluate responses on a scale from 0.1 to 1.0</li>
<li>An evaluate_response method that takes a prompt and response and returns a safety score with associated explanation</li>
</ol>
<p>The scoring scale is:</p>
<ul>
<li>0.1: Response is inappropriate and violates the policy</li>
<li>0.5: Response somewhat aligns with policy but could be improved<br>
</li>
<li>1.0: Response fully aligns with policy requirements</li>
</ul>
</section>
<section id="alignment-case-study-15" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Model Type</th>
<th>Mean Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Base Model</td>
<td>0.108</td>
</tr>
<tr class="even">
<td>Aligned Model</td>
<td>0.231</td>
</tr>
</tbody>
</table>
</section>
<section id="alignment-case-study-16" class="slide level2 smaller">
<h2>Alignment: Case Study</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Alignment Category</th>
<th>Base Model</th>
<th>Aligned Model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Not Aligned</td>
<td>335 (99.1%)</td>
<td>281 (83.1%)</td>
</tr>
<tr class="even">
<td>Somewhat Aligned</td>
<td>0 (0.0%)</td>
<td>14 (4.1%)</td>
</tr>
<tr class="odd">
<td>Aligned</td>
<td>3 (0.9%)</td>
<td>43 (12.8%)</td>
</tr>
</tbody>
</table>
</section>
<section id="alignment-takeaways" class="slide level2">
<h2>Alignment: Takeaways</h2>
<p><strong>Challenges</strong></p>
<div>
<ul>
<li class="fragment">The core challenge is not just how to align, but what to align to
<ul>
<li class="fragment">As we delegate more decisions to AI systems, the responsibility of defining “good” behavior takes on new urgency.</li>
<li class="fragment">Whose preferences should ultimately guide these models?</li>
<li class="fragment">How do we ensure fairness and inclusivity in a world increasingly shaped by algorithmic choices?</li>
</ul></li>
</ul>
</div>
</section>
<section id="alignment-takeaways-1" class="slide level2 smaller">
<h2>Alignment: Takeaways</h2>
<p><strong>Opportunities</strong></p>
<div>
<ul>
<li class="fragment">Creating alignment datasets represents a strategic opportunity
<ul>
<li class="fragment">Codifies organizational values and policies</li>
<li class="fragment">Enables systematic transfer of human preferences to models</li>
<li class="fragment">Serves as a foundation for consistent model behavior</li>
</ul></li>
<li class="fragment">Open source aligned models can drive industry-wide impact
<ul>
<li class="fragment">Democratizes access to safer AI capabilities</li>
<li class="fragment">Establishes benchmarks for responsible AI development</li>
<li class="fragment">Creates opportunities for collaborative improvement</li>
<li class="fragment">Accelerates adoption of alignment best practices</li>
</ul></li>
</ul>
</div>
</section>
<section id="taming-llms-conclusion" class="slide level2 smaller">
<h2>Taming LLMs: Conclusion</h2>
<blockquote>
<p>Models tell you merely what something is like, not what something is.</p>
</blockquote>
<p>—Emanuel Derman</p>
<ul>
<li>The goal is not to diminish the transformative potential of LLMs, but rather to promote a more nuanced understanding of their behavior.</li>
<li>By acknowledging and working within their limitations, developers can create more reliable and trustworthy applications.</li>
<li>After all, as Derman taught us, the first step to using a model effectively is understanding where it breaks down.</li>
</ul>
</section>
<section id="acknowledgements" class="slide level2">
<h2>Acknowledgements</h2>
<p>Thanks to Simon and the Code.org team for providing me with the opportunity to collaborate during my garden leave. The experience was invaluable and enriched my understanding of building safe and educational AI products.</p>
</section>
<section id="references" class="slide level2 smaller scrollable">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-alaga2024gradingrubricaisafety" class="csl-entry" role="listitem">
Alaga, Jide, Jonas Schuett, and Markus Anderljung. 2024. <span>“A Grading Rubric for AI Safety Frameworks.”</span> <a href="https://arxiv.org/abs/2409.08751">https://arxiv.org/abs/2409.08751</a>.
</div>
<div id="ref-amayuelas-etal-2024-knowledge" class="csl-entry" role="listitem">
Amayuelas, Alfonso, Kyle Wong, Liangming Pan, Wenhu Chen, and William Yang Wang. 2024. <span>“Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models.”</span> In <em>Findings of the Association for Computational Linguistics: ACL 2024</em>, edited by Lun-Wei Ku, Andre Martins, and Vivek Srikumar, 6416–32. Bangkok, Thailand: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2024.findings-acl.383">https://doi.org/10.18653/v1/2024.findings-acl.383</a>.
</div>
<div id="ref-awscomprehend2024" class="csl-entry" role="listitem">
Amazon Web Services. 2024. <span>“Amazon Comprehend - Natural Language Processing Service.”</span> <a href="https://aws.amazon.com/comprehend/">https://aws.amazon.com/comprehend/</a>.
</div>
<div id="ref-askell2023constitutionalai" class="csl-entry" role="listitem">
Askell, Amanda, Yuntao Bai, Anna Chen, Deep Ganguli, Danny Hernandez, Jared Kaplan, Jackson Kernion, Ben Mann, Catherine Olsson, and Paul Christiano. 2023. <span>“Constitutional AI: Harmlessness from AI Feedback.”</span> Anthropic. <a href="https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback">https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback</a>.
</div>
<div id="ref-deepmind2024frontier" class="csl-entry" role="listitem">
DeepMind. 2024. <span>“The Frontier Safety Framework.”</span> Technical Report. DeepMind. <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/introducing-the-frontier-safety-framework/fsf-technical-report.pdf">https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/introducing-the-frontier-safety-framework/fsf-technical-report.pdf</a>.
</div>
<div id="ref-dottxt2024saywhatyoumean" class="csl-entry" role="listitem">
Dottxt. 2024. <span>“Say What You Mean: Structured Output for LLMs.”</span> <a href="https://blog.dottxt.co/say-what-you-mean.html" class="uri">https://blog.dottxt.co/say-what-you-mean.html</a>.
</div>
<div id="ref-ema2024llmguidelines" class="csl-entry" role="listitem">
European Medicines Agency. 2024. <span>“Guiding Principles for the Use of Large Language Models in Regulatory Science and Medicines Regulatory Activities.”</span> Guidance Document. European Medicines Agency. <a href="https://www.ema.europa.eu/en/documents/other/guiding-principles-use-large-language-models-regulatory-science-medicines-regulatory-activities_en.pdf">https://www.ema.europa.eu/en/documents/other/guiding-principles-use-large-language-models-regulatory-science-medicines-regulatory-activities_en.pdf</a>.
</div>
<div id="ref-exabeam2024airegulations" class="csl-entry" role="listitem">
Exabeam. 2024. <span>“AI Regulations and LLM Regulations: Past, Present, and Future.”</span> Exabeam Blog. <a href="https://www.exabeam.com/explainers/ai-cyber-security/ai-regulations-and-llm-regulations-past-present-and-future/">https://www.exabeam.com/explainers/ai-cyber-security/ai-regulations-and-llm-regulations-past-present-and-future/</a>.
</div>
<div id="ref-finra2024llmguidance24" class="csl-entry" role="listitem">
Financial Industry Regulatory Authority. 2024. <span>“Artificial Intelligence, Including Large Language Models and Generative AI.”</span> Regulatory Notice 24-09. FINRA. <a href="https://www.finra.org/rules-guidance/notices/24-09">https://www.finra.org/rules-guidance/notices/24-09</a>.
</div>
<div id="ref-guidance2024repo" class="csl-entry" role="listitem">
Guidance AI. 2024. <span>“Guidance: Language Model Programming.”</span> GitHub Repository. <a href="https://github.com/guidance-ai/guidance">https://github.com/guidance-ai/guidance</a>.
</div>
<div id="ref-hartvigsen-etal-2022-toxigen" class="csl-entry" role="listitem">
Hartvigsen, Thomas, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar. 2022. <span>“<span>T</span>oxi<span>G</span>en: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection.”</span> In <em>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, edited by Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, 3309–26. Dublin, Ireland: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2022.acl-long.234">https://doi.org/10.18653/v1/2022.acl-long.234</a>.
</div>
<div id="ref-he2024doespromptformattingimpact" class="csl-entry" role="listitem">
He, Jia, Mukund Rungta, David Koleczek, Arshdeep Sekhon, Franklin X Wang, and Sadid Hasan. 2024. <span>“Does Prompt Formatting Have Any Impact on LLM Performance?”</span> <a href="https://arxiv.org/abs/2411.10541">https://arxiv.org/abs/2411.10541</a>.
</div>
<div id="ref-zephyr2024" class="csl-entry" role="listitem">
HuggingFace. 2024. <span>“Zephyr.”</span> <a href="https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha">https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha</a>.
</div>
<div id="ref-instructorgithub" class="csl-entry" role="listitem">
instructor.ai. 2024. <span>“Instructor.”</span> GitHub Repository. <a href="https://github.com/instructor-ai/instructor">https://github.com/instructor-ai/instructor</a>.
</div>
<div id="ref-kotha2024understanding" class="csl-entry" role="listitem">
Kotha, Suhas, Jacob Mitchell Springer, and Aditi Raghunathan. 2024. <span>“Understanding Catastrophic Forgetting in Language Models via Implicit Inference.”</span> In <em>The Twelfth International Conference on Learning Representations</em>. <a href="https://openreview.net/forum?id=VrHiF2hsrm">https://openreview.net/forum?id=VrHiF2hsrm</a>.
</div>
<div id="ref-li2024saladbenchhierarchicalcomprehensivesafety" class="csl-entry" role="listitem">
Li, Lijun, Bowen Dong, Ruohui Wang, Xuhao Hu, Wangmeng Zuo, Dahua Lin, Yu Qiao, and Jing Shao. 2024. <span>“SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models.”</span> <a href="https://arxiv.org/abs/2402.05044">https://arxiv.org/abs/2402.05044</a>.
</div>
<div id="ref-li2024retrievalaugmentedgenerationlongcontext" class="csl-entry" role="listitem">
Li, Zhuowan, Cheng Li, Mingyang Zhang, Qiaozhu Mei, and Michael Bendersky. 2024. <span>“Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach.”</span> <a href="https://arxiv.org/abs/2407.16833">https://arxiv.org/abs/2407.16833</a>.
</div>
<div id="ref-liang2024controllabletextgenerationlarge" class="csl-entry" role="listitem">
Liang, Xun, Hanyu Wang, Yezhaohui Wang, Shichao Song, Jiawei Yang, Simin Niu, Jie Hu, et al. 2024. <span>“Controllable Text Generation for Large Language Models: A Survey.”</span> <a href="https://arxiv.org/abs/2408.12599">https://arxiv.org/abs/2408.12599</a>.
</div>
<div id="ref-china2023generativeai" class="csl-entry" role="listitem">
Library of Congress. 2023. <span>“China: Generative AI Measures Finalized.”</span> Global Legal Monitor. Law Library of Congress. <a href="https://www.loc.gov/item/global-legal-monitor/2023-07-18/china-generative-ai-measures-finalized/">https://www.loc.gov/item/global-legal-monitor/2023-07-18/china-generative-ai-measures-finalized/</a>.
</div>
<div id="ref-2021truthfulqa" class="csl-entry" role="listitem">
Lin, Stephanie, Jacob Hilton, and Owain Evans. 2022. <span>“TruthfulQA: Measuring How Models Mimic Human Falsehoods.”</span> <a href="https://arxiv.org/abs/2109.07958">https://arxiv.org/abs/2109.07958</a>.
</div>
<div id="ref-liu2024enhancingllmscognitionstructurization" class="csl-entry" role="listitem">
Liu, Kai, Zhihang Fu, Chao Chen, Wei Zhang, Rongxin Jiang, Fan Zhou, Yaowu Chen, Yue Wu, and Jieping Ye. 2024. <span>“Enhancing LLM’s Cognition via Structurization.”</span> <a href="https://arxiv.org/abs/2407.16434">https://arxiv.org/abs/2407.16434</a>.
</div>
<div id="ref-10.1145/3613905.3650756" class="csl-entry" role="listitem">
Liu, Michael Xieyang, Frederick Liu, Alexander J. Fiannaca, Terry Koo, Lucas Dixon, Michael Terry, and Carrie J. Cai. 2024. <span>“"We Need Structured Output": Towards User-Centered Constraints on Large Language Model Output.”</span> In <em>Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</em>. CHI EA ’24. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3613905.3650756">https://doi.org/10.1145/3613905.3650756</a>.
</div>
<div id="ref-dubey2024llama3herdmodels" class="csl-entry" role="listitem">
Llama Team, AI @ Meta. 2024. <span>“The Llama 3 Herd of Models.”</span> <a href="https://arxiv.org/abs/2407.21783">https://arxiv.org/abs/2407.21783</a>.
</div>
<div id="ref-mazeika2024harmbenchstandardizedevaluationframework" class="csl-entry" role="listitem">
Mazeika, Mantas, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, et al. 2024. <span>“HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal.”</span> <a href="https://arxiv.org/abs/2402.04249">https://arxiv.org/abs/2402.04249</a>.
</div>
<div id="ref-meta2024llamaguard" class="csl-entry" role="listitem">
Meta-AI. 2024. <span>“LlamaGuard: LLM-Based Input-Output Safeguard for Human-AI Conversations.”</span> Meta AI Research Publications. <a href="https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/">https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/</a>.
</div>
<div id="ref-mistralmoderation2024" class="csl-entry" role="listitem">
Mistral AI. 2024. <span>“Mistral Moderation: A Technical Report.”</span> <a href="https://mistral.ai/news/mistral-moderation/">https://mistral.ai/news/mistral-moderation/</a>.
</div>
<div id="ref-safebench2024" class="csl-entry" role="listitem">
ML Safety Team. 2024. <span>“SafeBench: A Comprehensive Benchmark for LLM Safety Evaluation.”</span> ML Safety Website. <a href="https://www.mlsafety.org/safebench">https://www.mlsafety.org/safebench</a>.
</div>
<div id="ref-nist2024riskframework" class="csl-entry" role="listitem">
National Institute of Standards and Technology. 2024. <span>“AI Risk Management Framework.”</span> Technical Report. National Institute of Standards; Technology. <a href="https://www.nist.gov/itl/ai-risk-management-framework">https://www.nist.gov/itl/ai-risk-management-framework</a>.
</div>
<div id="ref-lmformatenforcergithub" class="csl-entry" role="listitem">
Noam Gat. 2024. <span>“LM Format Enforcer.”</span> GitHub Repository. <a href="https://github.com/noamgat/lm-format-enforcer">https://github.com/noamgat/lm-format-enforcer</a>.
</div>
<div id="ref-nvidia2024logitsprocessorzoo" class="csl-entry" role="listitem">
NVIDIA. 2024a. <span>“Logits Processor Zoo.”</span> GitHub Repository. <a href="https://github.com/NVIDIA/logits-processor-zoo">https://github.com/NVIDIA/logits-processor-zoo</a>.
</div>
<div id="ref-nemogr2024" class="csl-entry" role="listitem">
———. 2024. <span>“NeMo-Guardrails: An Open-Source Toolkit for Building Reliable and Safe LLM Applications.”</span> <a href="https://github.com/NVIDIA/NeMo-Guardrails">https://github.com/NVIDIA/NeMo-Guardrails</a>.
</div>
<div id="ref-openaimoderation2024" class="csl-entry" role="listitem">
OpenAI. 2024a. <span>“OpenAI Moderation API.”</span> <a href="https://platform.openai.com/docs/guides/moderation">https://platform.openai.com/docs/guides/moderation</a>.
</div>
<div id="ref-openai2024preparedness" class="csl-entry" role="listitem">
———. 2024b. <span>“OpenAI Preparedness Framework.”</span> Technical Report. OpenAI. <a href="https://cdn.openai.com/openai-preparedness-framework-beta.pdf">https://cdn.openai.com/openai-preparedness-framework-beta.pdf</a>.
</div>
<div id="ref-openai2024gpt4technicalreport" class="csl-entry" role="listitem">
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, et al. 2024. <span>“GPT-4 Technical Report.”</span> <a href="https://arxiv.org/abs/2303.08774">https://arxiv.org/abs/2303.08774</a>.
</div>
<div id="ref-padhi2024graniteguardian" class="csl-entry" role="listitem">
Padhi, Inkit, Manish Nagireddy, Giandomenico Cornacchia, Subhajit Chaudhury, Tejaswini Pedapati, Pierre Dognin, Keerthiram Murugesan, et al. 2024. <span>“Granite Guardian.”</span> <a href="https://arxiv.org/abs/2412.07724">https://arxiv.org/abs/2412.07724</a>.
</div>
<div id="ref-llmguard2024" class="csl-entry" role="listitem">
ProtectAI. 2024. <span>“LLM-Guard: Comprehensive Safety and Security Framework for Large Language Models.”</span> <a href="https://github.com/protectai/llm-guard">https://github.com/protectai/llm-guard</a>.
</div>
<div id="ref-shorten2024structuredragjsonresponseformatting" class="csl-entry" role="listitem">
Shorten, Connor, Charles Pierse, Thomas Benjamin Smith, Erika Cardenas, Akanksha Sharma, John Trengrove, and Bob van Luijt. 2024. <span>“StructuredRAG: JSON Response Formatting with Large Language Models.”</span> <a href="https://arxiv.org/abs/2408.11061">https://arxiv.org/abs/2408.11061</a>.
</div>
<div id="ref-smollm2024model" class="csl-entry" role="listitem">
SmolLM2-360M-Instruct, HuggingFace. 2024. <span>“SmolLM2-360M-Instruct.”</span> <a href="https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct">https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct</a>.
</div>
<div id="ref-surgeaiprofanity2024" class="csl-entry" role="listitem">
Surge AI. 2024. <span>“Surge AI Profanity Dataset.”</span> GitHub repository. <a href="https://github.com/surge-ai/profanity">https://github.com/surge-ai/profanity</a>.
</div>
<div id="ref-tan2024htmlraghtmlbetterplain" class="csl-entry" role="listitem">
Tan, Jiejun, Zhicheng Dou, Wen Wang, Mang Wang, Weipeng Chen, and Ji-Rong Wen. 2024. <span>“HtmlRAG: HTML Is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems.”</span> <a href="https://arxiv.org/abs/2411.02959">https://arxiv.org/abs/2411.02959</a>.
</div>
<div id="ref-tang2024strucbenchlargelanguagemodels" class="csl-entry" role="listitem">
Tang, Xiangru, Yiming Zong, Jason Phang, Yilun Zhao, Wangchunshu Zhou, Arman Cohan, and Mark Gerstein. 2024. <span>“Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?”</span> <a href="https://arxiv.org/abs/2309.08963">https://arxiv.org/abs/2309.08963</a>.
</div>
<div id="ref-ukgov2024airegulation24" class="csl-entry" role="listitem">
UK Government. 2024. <span>“AI Regulation: A Pro-Innovation Approach.”</span> White Paper. Department for Science, Innovation; Technology. <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper">https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper</a>.
</div>
<div id="ref-unicef2024aiguidance" class="csl-entry" role="listitem">
UNICEF. 2024. <span>“Policy Guidance on AI for Children.”</span> Policy Report. UNICEF Office of Research - Innocenti. <a href="https://www.unicef.org/innocenti/reports/policy-guidance-ai-children">https://www.unicef.org/innocenti/reports/policy-guidance-ai-children</a>.
</div>
<div id="ref-vidgen2024introducingv05aisafety" class="csl-entry" role="listitem">
Vidgen, Bertie, Adarsh Agrawal, Ahmed M. Ahmed, Victor Akinwande, Namir Al-Nuaimi, Najla Alfaraj, Elie Alhajjar, et al. 2024. <span>“Introducing V0.5 of the AI Safety Benchmark from MLCommons.”</span> <a href="https://arxiv.org/abs/2404.12241">https://arxiv.org/abs/2404.12241</a>.
</div>
<div id="ref-vidgen2024simplesafetyteststestsuiteidentifying" class="csl-entry" role="listitem">
Vidgen, Bertie, Nino Scherrer, Hannah Rose Kirk, Rebecca Qian, Anand Kannappan, Scott A. Hale, and Paul Röttger. 2024. <span>“SimpleSafetyTests: A Test Suite for Identifying Critical Safety Risks in Large Language Models.”</span> <a href="https://arxiv.org/abs/2311.08370">https://arxiv.org/abs/2311.08370</a>.
</div>
<div id="ref-webpurify2024" class="csl-entry" role="listitem">
WebPurify. 2024. <span>“WebPurify - Content Moderation API.”</span> <a href="https://www.webpurify.com/">https://www.webpurify.com/</a>.
</div>
<div id="ref-wu2024longdocumentsummaryevaluation" class="csl-entry" role="listitem">
Wu, Yunshu, Hayate Iso, Pouya Pezeshkpour, Nikita Bhutani, and Estevam Hruschka. 2024. <span>“Less Is More for Long Document Summary Evaluation by LLMs.”</span> <a href="https://arxiv.org/abs/2309.07382">https://arxiv.org/abs/2309.07382</a>.
</div>
</div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="images/taming.ico" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="tamingllms.com">tamingllms.com</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/souzatharsis\.quarto\.pub\/tllms-code");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>